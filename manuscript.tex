% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  man]{apa7}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
\ifLuaTeX
\usepackage[bidi=basic]{babel}
\else
\usepackage[bidi=default]{babel}
\fi
\babelprovide[main,import]{english}
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
% Manuscript styling
\usepackage{upgreek}
\captionsetup{font=singlespacing,justification=justified}

% Table formatting
\usepackage{longtable}
\usepackage{lscape}
% \usepackage[counterclockwise]{rotating}   % Landscape page setup for large tables
\usepackage{multirow}		% Table styling
\usepackage{tabularx}		% Control Column width
\usepackage[flushleft]{threeparttable}	% Allows for three part tables with a specified notes section
\usepackage{threeparttablex}            % Lets threeparttable work with longtable

% Create new environments so endfloat can handle them
% \newenvironment{ltable}
%   {\begin{landscape}\centering\begin{threeparttable}}
%   {\end{threeparttable}\end{landscape}}
\newenvironment{lltable}{\begin{landscape}\centering\begin{ThreePartTable}}{\end{ThreePartTable}\end{landscape}}

% Enables adjusting longtable caption width to table width
% Solution found at http://golatex.de/longtable-mit-caption-so-breit-wie-die-tabelle-t15767.html
\makeatletter
\newcommand\LastLTentrywidth{1em}
\newlength\longtablewidth
\setlength{\longtablewidth}{1in}
\newcommand{\getlongtablewidth}{\begingroup \ifcsname LT@\roman{LT@tables}\endcsname \global\longtablewidth=0pt \renewcommand{\LT@entry}[2]{\global\advance\longtablewidth by ##2\relax\gdef\LastLTentrywidth{##2}}\@nameuse{LT@\roman{LT@tables}} \fi \endgroup}

% \setlength{\parindent}{0.5in}
% \setlength{\parskip}{0pt plus 0pt minus 0pt}

% Overwrite redefinition of paragraph and subparagraph by the default LaTeX template
% See https://github.com/crsh/papaja/issues/292
\makeatletter
\renewcommand{\paragraph}{\@startsection{paragraph}{4}{\parindent}%
  {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
  {-1em}%
  {\normalfont\normalsize\bfseries\itshape\typesectitle}}

\renewcommand{\subparagraph}[1]{\@startsection{subparagraph}{5}{1em}%
  {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
  {-\z@\relax}%
  {\normalfont\normalsize\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
\makeatother

\makeatletter
\usepackage{etoolbox}
\patchcmd{\maketitle}
  {\section{\normalfont\normalsize\abstractname}}
  {\section*{\normalfont\normalsize\abstractname}}
  {}{\typeout{Failed to patch abstract.}}
\patchcmd{\maketitle}
  {\section{\protect\normalfont{\@title}}}
  {\section*{\protect\normalfont{\@title}}}
  {}{\typeout{Failed to patch title.}}
\makeatother

\usepackage{xpatch}
\makeatletter
\xapptocmd\appendix
  {\xapptocmd\section
    {\addcontentsline{toc}{section}{\appendixname\ifoneappendix\else~\theappendix\fi\\: #1}}
    {}{\InnerPatchFailed}%
  }
{}{\PatchFailed}
\keywords{multigroup confirmatory factor analysis, measurement invariance, visualization, effect size}
\DeclareDelayedFloatFlavor{ThreePartTable}{table}
\DeclareDelayedFloatFlavor{lltable}{table}
\DeclareDelayedFloatFlavor*{longtable}{table}
\makeatletter
\renewcommand{\efloat@iwrite}[1]{\immediate\expandafter\protected@write\csname efloat@post#1\endcsname{}}
\makeatother
\usepackage{lineno}

\linenumbers
\usepackage{csquotes}
\makeatletter
\renewcommand{\paragraph}{\@startsection{paragraph}{4}{\parindent}%
  {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
  {-1em}%
  {\normalfont\normalsize\bfseries\typesectitle}}

\renewcommand{\subparagraph}[1]{\@startsection{subparagraph}{5}{1em}%
  {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
  {-\z@\relax}%
  {\normalfont\normalsize\bfseries\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
\makeatother

\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Visualizing and Interpreting Multi-Group Confirmatory Factor Analysis},
  pdfauthor={Erin M. Buchanan1},
  pdflang={en-EN},
  pdfkeywords={multigroup confirmatory factor analysis, measurement invariance, visualization, effect size},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Visualizing and Interpreting Multi-Group Confirmatory Factor Analysis}
\author{Erin M. Buchanan\textsuperscript{1}}
\date{}


\shorttitle{VISUAL MGCFA}

\authornote{

Thank you to K.D. Valentine and Chelsea Parlett-Pelleriti for feedback on some ugly graphs.

Correspondence concerning this article should be addressed to Erin M. Buchanan, 326 Market St., Harrisburg, PA, USA. E-mail: \href{mailto:ebuchanan@harrisburgu.edu}{\nolinkurl{ebuchanan@harrisburgu.edu}}

}

\affiliation{\vspace{0.5cm}\textsuperscript{1} Harrisburg University of Science and Technology}

\abstract{%
Latent variable modeling as a lens for psychometric theory is a popular tool for social scientists to examine measurement of constructs (Beaujean, 2014). Journals such as \emph{Assessment} regularly publish articles supporting measures of latent constructs wherein a measurement model is established. Confirmatory factor analysis can be used to investigate the replicability and generalizability of the measurement model in new samples, while multi-group confirmatory factor analysis is used to examine the measurement model across groups within samples (Brown, 2015). With the rise of the replication crisis and ``psychology's renaissance'' (Nelson et al., 2018), interest in divergence in measurement has increased, often focused on small parameter differences within the latent model. This manuscript outlines ways to visualize potential non-invariance, to supplement large numbers of tables that often overwhelm a reader within these published reports. Readers will learn how to interpret the impact and size of the proposed non-invariance in models. While it is tempting to suggest that problems with replication and generalizability are simply issues with measurement, it is crucial to remember that all models have variability and error, even those models estimating the differences between item functioning, such as multi-group confirmatory factor analysis.
}



\begin{document}
\maketitle

Psychological assessments play a critical role in our ability to measure and analyze constructs to support theories and experimental hypotheses. Defining and creating assessments to validly and reliability measure constructs is often difficult because phenomenon, such as anxiety, are often not directly observable. Instead, we use surveys and questionnaires to indirectly assess the underlying construct (DeVellis \& Thorpe, 2022). Latent variable modeling (i.e., structural equation modeling) is a popular tool for the validation of developed survey instruments to verify scale dimensionality, structure, and model fit. A simple search for scale development reveals thousands of articles in psychology that examine new and previously published work, thus, illustrating the interest in both measurement and the use of validation techniques. Unfortunately, except in specialty journals, much of the validity evidence and/or development for measures used in empirical studies is not reported within the journal article (Barry et al., 2014; Weidman et al., 2017). Without this information, it is difficult to interpret individual study conclusions, as validity information allows for judgment of usefulness of the measured values (Flake \& Fried, 2020). Further, the current focus on replication (Makel et al., 2012; Makel \& Plucker, 2014; Zwaan et al., 2018), reproducibility (Nelson et al., 2018), and the credibility of our results (Vazire et al., 2022) has demonstrated questionable measurement practices - decisions that researchers make like survey selection and scoring that impact the results of the study (Flake \& Fried, 2020). Transparent reporting of the use and creation of scales can improve both interpretation and reproducibility when using surveys developed to measure latent constructs (Shadish et al., 2001).

A secondary concern for developed measures is the potential for differential responding and assessment within target populations. For example, Trent et al. (2013) examined for potential variability in the Revised Child Anxiety and Depression Scale in White and Black youths (Chorpita et al., 2000). They found that the scale mostly functioned the same for both White and Black individuals but differences in averages on individual items could potentially affect the scoring and interpretation of the scale results. This comparison of sub-populations is the test of measurement invariance (Meredith, 1993). Invariance or equivalence implies that the scale operates in the same fashion for each sub-group, and thus, differences in the final latent variable scores can interpreted as differences in populations. Non-invariance suggests that individuals respond or interpret items differently, and thus, differences in scores may represent different scores on the latent variable in the population or differences in measurement. Non-invariant measurement may lead to misleading results when making group comparisons, and assessing invariance has become a popular technique in scale development (Van De Schoot et al., 2015).

Measurement invariance is typically analyzed using confirmatory factor analysis, specifically, multi-group confirmatory factor analysis (MGCFA) or less often, with item response theory (Stark et al., 2006; Tay et al., 2015). First, the model is examined with the factor structure proposed for the latent and observed variables, and then often these models are assessed for each group separately. The two models are then combined together into one nested CFA in order to determine configural invariance (Brown, 2015; Byrne, 2001; Kline, 2016). Configural invariance tests if the proposed factor structure is the same between groups. In this model, all other estimated parameters are allowed to vary between groups. The general approach is to use this model as a baseline for starting a sequential analysis of further restrictions between group parameters (i.e., more restrictive with each step). However, models without configural invariance can occur and often point to misspecification for the observed and latent variables within one group (i.e., cross loadings of items onto other latent variables or correlated error terms for one group only).

Next, the estimated parameter between each observed variable and its latent variable are constrained to be equal between groups for metric invariance. For example, item 1's factor loading must be equal to item 1's factor loading for each group. This test examines if the items represent the same relationship to the latent variable, or if specific items have weaker or stronger relationships in specific groups. Finding non-invariance at this stage generally points to items that have different functioning or interpretation for one group. At the third model, the item intercepts (i.e., item averages) are restricted across groups for scalar invariance. Scalar non-invariance would indicate that items have the same strength of relationship with their latent variable, just one group has a higher overall average on that item. Last (although sometimes not used), we may consider constraining error variances for each observed variable to be equal across groups for strict invariance. Strict non-invariance can occur when one group has a higher range of values on the observed variable, thus showing a larger variance. For example, if using a Likert scale, one group may use the full 1 to 7 range (creating a flatter distribution and larger variance), while the other group shows a ceiling effect of only using 5 to 7.

These concepts have been explored and implemented for the last fifty years (Jöreskog, 1971; Sörbom, 1978) and implemented in the most popular structural equation modeling programs (Boker et al., 2011; Jöreskog \& Sörbom, 2001; Rosseel, 2012). Byrne et al. (1989) extended the ideas of multi-group testing by suggesting partial invariance (followed by Meredith, 1993). Partial invariance occurs when non-invariance is found but can be attributed to only a few parameter estimate differences between groups (i.e., items 1 and 2 have different factor loadings but all others are the same). This testing provided an advantage to understand where the potential non-invariance may occur for further study and interpretation guidelines. To determine when non-invariance and partial invariance occurred, each model is sequentially compared to the previous model using some form of a difference test. Traditionally, since models were nested, a chi-square difference test was used (Cheung \& Rensvold, 2002; Meade et al., 2008); however, given the known issues with chi-square (Thompson \& Daniel, 1996), people have favored empirical cutoffs for differences in fit indices. As the field pushes back against favoring cutoff criteria and rules of thumb (Marsh et al., 2004; Putnick \& Bornstein, 2016), an effect size measure for translating ``how much'' non-invariance was developed \(d_{MACS}\) (Nye \& Drasgow, 2011). This effect size examines the differences in observed variables between the two groups for both the factor loading and the item intercept; thus, any differences in either or both will increase the effect size for non-invariance (Stark et al., 2006).

With \(d_{MACS}\) and measurement invariance testing, researchers can begin to quantify how and where their construct measurement may vary between groups. However, given the large number of studies that show non-invariance, it is clear that equivalence can be hard to meet. It is difficult to know if non-invariance occurs because of random sampling error, true population differences, or differences in replication and reproducibility of the construct in a new sample. Further, it is important to remember that the parameter estimates that we are testing are just that - estimates. All the parameter estimates have measures of standard error to indicate that they are more than likely variable with a new sample or population. Given that this information is generally ignored during the examination of measurement invariance, it may be that we are claiming that many scales are non-invariant, when in reality, the differences between loadings or item intercepts are small and unimportant. \(d_{MACS}\) provides the opportunity to begin to think about the smallest effect size of interest or the smallest meaningful effect size (Anvari \& Lakens, 2021; Lakens, 2017). As mentioned, \(d_{MACS}\) has only really been explored for a combined intercept and loadings, and while useful, does not necessarily allow a researcher to pinpoint specific issues within an observed variable. The purpose of this manuscript is provide readers with a framework for visualization of differences in loadings, intercepts, and variances for each item, and the impact of those differences on the distribution of the latent mean. No known visualization techniques have been proposed for measurement invariance. By creating panel visualizations, we can supplement a researchers ability to judge the strength of the non-invariance differences and effect size for each item. Coupled with other indicators (i.e., fit indices differences, \(d_{MACS}\)), we can move toward a better understanding of how much measurement non-invariance is meaningful.

By the end of this tutorial manuscript, readers will:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Be able to create visualizations for common steps to multi-group confirmatory factor analysis.
\item
  Be able to interpret the impact and size of potential non-invariance on measurement.
\item
  Understand the impact of measurement variability on replication and generalizability.
\end{enumerate}

\hypertarget{method}{%
\section{Method}\label{method}}

\hypertarget{design-and-analysis}{%
\subsection{Design and Analysis}\label{design-and-analysis}}

Data was simulated using the \texttt{simulateData} function in the \emph{R} package \emph{lavaan} (Rosseel, 2012) assuming multivariate normality using a \(\mu\) of 0 and \(\sigma\) of 1 for the data. This function allows you to write \emph{lavaan} syntax for your model with estimated values to generate data for observed variables. The data included two groups of individuals (``Group 1'', ``Group 2'') for a multi-group confirmatory factor analysis (\(n_{group}\) = 250, \emph{N} = 500). The latent variables were assumed to be continuous normal. The model consisted of five observed items predicted by one latent variable (\texttt{lv\ =\textasciitilde{}\ q1\ +\ q2\ +\ q3\ +\ q4\ +\ q5}); however, the demonstration in this manuscript extends to multiple latent variables and other combinations of observed variables. Each item was assumed to be related to the latent variable with loadings approximately equal to .40 to .80, except when cases of non-invariance on the loadings was assumed.

The Brown (2015) steps of testing measurement invariance are demonstrated in this manuscript for illustration purposes, but in line with Stark et al. (2006) suggestions, the visualizations show the impact of loadings and intercepts together. The configural model was analyzed nesting both groups into the same CFA model requiring that both groups show the same model structure, but all other parameters are free to vary between groups. The metric model constrained the factor loadings of each group to be equal within the model. The scalar model then constrained the item intercepts (i.e., item means) to be equal across groups. Finally, the strict model constrained the item variances (i.e., error variances) to be equal for each item across groups. These models are normally tested sequentially, and a convenience function \texttt{mgcfa} is provided in the supplemental documents for this manuscript. Fit indices for the steps for multi-group models are presented in the appendix for comparison of cutoff rules of thumb (Cheung \& Rensvold, 2002) to effect sizes and visualizations presented in this manuscript. Fit indices include Akaike Information Criterion (AIC, Akaike, 1998), Bayesian Information Criterion (BIC, Schwarz, 1978), Comparative Fit Index (CFI, Bentler, 1990), Tucker Lewis Index (TLI, Tucker \& Lewis, 1973), root mean squared error of approximation RMSEA (Steiger, 1990), and standardized root mean square residual (SRMR, Bentler, 1995).

The data was then simulated to represent invariance across all model steps, small, medium, and large invariance using \(d_{MACS}\) estimated sizes from Nye et al. (2019). While \(d_{MACS}\) is used primarily for an effect size of the (non)-invariance for intercepts and loadings together, a similar approach was taken for the estimation of small, medium, and large effects on the residuals. The effect size is presented for all models, calculated from the \emph{dmacs} package (Dueber, 2023; Nye \& Drasgow, 2011). Only one item in each model was manipulated from the invariant model to create the non-invariant models.

\hypertarget{results}{%
\section{Results}\label{results}}

\hypertarget{code-examples}{%
\subsection{Code Examples}\label{code-examples}}

The complete code for this manuscript can be found at \url{https://osf.io/wev5f/}, and the function code for the convenience function for multi-group models and plots is found in the appendix. This tutorial was registered at \url{https://osf.io/vwf4d}, and the example provided at the end of the manuscript was added after that registration. First, we would create our model code in \emph{lavaan} syntax (Rosseel, 2012). The \texttt{lv} latent variable predicts the five measured variables, which are present as columns in our \texttt{df.invariant} data set. You would include the dataframe in the \texttt{data} argument of our function, the name of the grouping variable in quotes for \texttt{group}, and the \emph{lavaan} model syntax in the \texttt{model} argument. The \texttt{mgcfa} function code runs an overall model with all data, regardless of group, each group separately on the model, then the steps described above: configural, metric, scalar, and strict invariance.

\emph{lavaan} automatically sets the mean (i.e., the intercept) for latent variables to zero. If we wish to visualize the impact of the changes in parameter estimates across groups on the latent means, we need to allow the latent mean estimation with \texttt{lv\ \textasciitilde{}\ 1}. However, adding this estimation into our model will create a non-identified model. To solve this problem, you can set one of the intercepts of another variable to a value to scale the model. Here we will set the scale of the model by using \texttt{q1\ \textasciitilde{}\ 0*1}, thus, scaling the expected means to zero. With simulation, this step is easy to know which variable to pick - we set the intercept on the variable we know did not show differences. In real data, you may wish to run the model steps \emph{without} setting this option, examine the results of a configural or separate models, and then add the option for the values most similar. Additionally, you could complete partial invariance steps to determine which value appears most consistent to fix.

\small

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# create lavaan model}
\NormalTok{model.overall }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{\# overall one{-}factor model}
\StringTok{lv =\textasciitilde{} q1 + q2 + q3 + q4 + q5}
\StringTok{\# set the intercept (mean) of q1 to zero}
\StringTok{q1 \textasciitilde{} 0*1}
\StringTok{\# allow the lv intercept to be freely estimated}
\StringTok{lv \textasciitilde{} 1"}
\CommentTok{\# look at the data}
\FunctionTok{head}\NormalTok{(df.invariant)}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{verbatim}
##           q1          q2          q3         q4         q5   group
## 1 -0.8903542 -0.81707530  0.06137292 -1.3236407 -1.7916418 Group 1
## 2  1.1054521 -0.03540948 -0.81299606  1.0028340 -0.1909127 Group 1
## 3  1.4555852  1.54083484  1.59084213 -0.3345967 -0.6865496 Group 1
## 4 -1.8745187 -1.27880245 -2.53565792 -1.0024193 -1.6253249 Group 1
## 5 -0.4449517 -0.17782974  1.05507079 -1.2615705  1.7536428 Group 1
## 6  0.2278813  0.71348845  1.63251893  0.6449847 -1.0055700 Group 1
\end{verbatim}

\small

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# run our mgcfa function to run all models}
\NormalTok{results.invariant }\OtherTok{\textless{}{-}} \FunctionTok{mgcfa}\NormalTok{(}\AttributeTok{data =}\NormalTok{ df.invariant, }\CommentTok{\#dataframe}
                           \AttributeTok{group =} \StringTok{"group"}\NormalTok{, }
                           \AttributeTok{model =}\NormalTok{ model.overall)}
\CommentTok{\# what is saved for you}
\FunctionTok{names}\NormalTok{(results.invariant)}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{verbatim}
## [1] "model_coef"       "model_fit"        "model.overall"    "model.group1"    
## [5] "model.group2"     "model.configural" "model.metric"     "model.scalar"    
## [9] "model.strict"
\end{verbatim}

The results are saved as a list and include the following:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  \texttt{model\_coef}: a tidy dataframe with \emph{all} model's coefficients saved from the \emph{lavaan} outputs. Note that we can see that the intercept \texttt{\textasciitilde{}1} is set for question 1 but freely estimated for the latent variable.
\end{enumerate}

\small

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results.invariant}\SpecialCharTok{$}\NormalTok{model\_coef[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{ , ]}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{verbatim}
## # A tibble: 10 x 13
##    term     op    estimate std.error statistic   p.value  std.lv std.all std.nox
##    <chr>    <chr>    <dbl>     <dbl>     <dbl>     <dbl>   <dbl>   <dbl>   <dbl>
##  1 "lv =~ ~ =~      1         0         NA     NA         0.780   0.598   0.598 
##  2 "lv =~ ~ =~      0.564     0.0864     6.52   6.99e-11  0.440   0.435   0.435 
##  3 "lv =~ ~ =~      0.748     0.105      7.12   1.09e-12  0.583   0.505   0.505 
##  4 "lv =~ ~ =~      0.338     0.0804     4.20   2.62e- 5  0.264   0.250   0.250 
##  5 "lv =~ ~ =~      0.904     0.120      7.52   5.48e-14  0.705   0.613   0.613 
##  6 "q1 ~1 " ~1      0         0         NA     NA         0       0       0     
##  7 "lv ~1 " ~1     -0.0187    0.0584    -0.320  7.49e- 1 -0.0239 -0.0239 -0.0239
##  8 "q1 ~~ ~ ~~      1.09      0.103     10.6    0         1.09    0.643   0.643 
##  9 "q2 ~~ ~ ~~      0.828     0.0604    13.7    0         0.828   0.811   0.811 
## 10 "q3 ~~ ~ ~~      0.997     0.0786    12.7    0         0.997   0.745   0.745 
## # i 4 more variables: model <chr>, block <int>, group <int>, label <chr>
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  \texttt{model\_fit}: a tidy dataframe with \emph{all} model's fit indices saved from the \emph{lavaan} outputs.
\end{enumerate}

\small

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(results.invariant}\SpecialCharTok{$}\NormalTok{model\_fit)}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{verbatim}
## # A tibble: 6 x 18
##    agfi   AIC   BIC   cfi chisq  npar  rmsea rmsea.conf.high   srmr   tli
##   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>           <dbl>  <dbl> <dbl>
## 1 0.979 7516. 7579. 0.994  6.37    15 0.0234          0.0697 0.0211 0.988
## 2 0.948 3766. 3819. 0.976  7.79    15 0.0473          0.108  0.0312 0.953
## 3 0.952 3762. 3815. 0.980  7.25    15 0.0424          0.104  0.0322 0.960
## 4 0.950 7528. 7654. 0.978 15.0     30 0.0449          0.0886 0.0317 0.956
## 5 0.942 7529. 7639. 0.954 24.7     26 0.0554          0.0905 0.0476 0.934
## 6 0.952 7523. 7616. 0.964 26.2     22 0.0428          0.0760 0.0488 0.960
## # i 8 more variables: converged <lgl>, estimator <chr>, ngroups <int>,
## #   missing_method <chr>, nobs <int>, norig <int>, nexcluded <int>, model <chr>
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Saved \emph{lavaan} fitted objects that you can use the \texttt{summary()}, \texttt{parameterEstimates()}, \texttt{fitIndices()}, etc. on. Overall model indicates the model without grouping variables testing all data on the proposed model structure. This model is then tested separately for each group (\texttt{model.group1}, \texttt{model.group2}). The final models follow the Brown (2015) naming convention for sequential steps for testing MGCFA for measurement invariance (\texttt{model.configural}, \texttt{model.metric}, \texttt{model.scalar}, \texttt{model.strict}).
\end{enumerate}

The results from the \texttt{model\_coef} table can then be used directly in the suggested plotting function. The plot outputs will be described below. First, here are the arguments for the function:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  \texttt{data\_coef}: A tidy dataframe of the parameter estimates from the models. This function assumes you have used \texttt{broom::tidy()} on the saved model from \emph{lavaan} and added a column called ``model'' with the name of the model step (Robinson et al., 2023). This function will only run for models that have used the grouping function (i.e., configural, metric, scalar, and strict or other combinations/steps you wish to examine).
\item
  \texttt{model\_step}: Which model do you want to plot? You should match this name to the one you want to extract from your model column in the \texttt{data\_coef}.
\item
  \texttt{item\_name}: Which observed variable from your model syntax do you want to plot? Please list this variable name exactly how it appears in the model.
\item
  \texttt{x\_limits}: What do you want the x-axis limits to be for your invariance plot? The default option is to assume the latent variable is standardized, and therefore, -1 to 1 is recommended. Use only two numbers, a lower and upper limit. This value also constrains the latent mean diagram to help zoom in on group differences because the scale of latent means is usually centered over zero. You can use this parameter to zoom out to a more traditional histogram using \texttt{c(-2,\ 2)}.
\item
  \texttt{y\_limits}: What do you want the y-axis limits to be for your invariance plot? Given that the latent variable is used to predict the observed values in the data, you could use the minimum and maximum values found in the data. If that range is large, consider reducing this value to be able to visualize the results (i.e., otherwise it may be too zoomed out to judge group differences). Use only two numbers, a lower and upper limit.
\item
  \texttt{ci\_level}: What confidence limit do you want to plot? Use 1 - \(\alpha\).
\item
  \texttt{model\_results}: In this argument, include the saved \emph{lavaan} output for the model listed in the \texttt{model\_step} argument.
\item
  \texttt{lv\_name}: Include the name of the latent variable, exactly how it is listed in your \emph{lavaan} syntax. You should plot the latent variable that the \texttt{item\_name} is linked to. If you have items that load onto multiple latent variables, you will need to make multiple plots.
\end{enumerate}

\small

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot\_mgcfa}\NormalTok{(}
  \AttributeTok{data\_coef =}\NormalTok{ results.invariant}\SpecialCharTok{$}\NormalTok{model\_coef, }\CommentTok{\# output from model\_coef}
  \AttributeTok{model\_step =} \StringTok{"Configural"}\NormalTok{, }\CommentTok{\# which model do you want to plot}
  \AttributeTok{item\_name =} \StringTok{"q4"}\NormalTok{, }\CommentTok{\# name of observed item}
  \AttributeTok{x\_limits =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{), }\CommentTok{\# latent variable limits to graph}
  \AttributeTok{y\_limits =} \FunctionTok{c}\NormalTok{(}\FunctionTok{min}\NormalTok{(df.invariant}\SpecialCharTok{$}\NormalTok{q4), }\FunctionTok{max}\NormalTok{(df.invariant}\SpecialCharTok{$}\NormalTok{q4)), }\CommentTok{\# Y min and max in data }
  \AttributeTok{ci\_level =}\NormalTok{ .}\DecValTok{95}\NormalTok{, }\CommentTok{\# what ci do you want}
  \AttributeTok{model\_results =}\NormalTok{ results.invariant}\SpecialCharTok{$}\NormalTok{model.configural, }\CommentTok{\# what model results do you want }
  \AttributeTok{lv\_name =} \StringTok{"lv"} \CommentTok{\# which latent variable do you want }
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\normalsize

\hypertarget{visualization-of-invariance}{%
\subsection{Visualization of Invariance}\label{visualization-of-invariance}}

The output from this model can be found in Figure \ref{fig:invariant-pic}. On the left hand side, the item invariance is plotted, and on the right hand side, the latent mean distributions for the two groups are plotted. In the item invariance sub-plot, the visualization includes all three components traditionally seen in MGCFA testing steps: loadings, intercepts, and residuals. Each visualization element was designed to match the traditional visualization for that type of output. All parameter estimates are plotted on the unstandardized estimates and their confidence interval based on the standard error of the estimate. All plots are made with \emph{ggplot2} (Wickham, 2016) and \emph{cowplot} (Wilke, 2020).

\hypertarget{loadings}{%
\subsubsection{Loadings}\label{loadings}}

Factor loadings represent the slope of the regression equation for the latent variable predicting the scores on the observed variable (\(\hat{Y} \sim b_0 + b_1X + \epsilon\)). Therefore, the latent variable is shown on the x-axis using standardized values (i.e., \emph{z}-scores) where -1 indicates one standard deviation below the mean for the latent variable, 0 indicates the mean for the latent variable and so on. The y-axis indicates the observed variable scores, and here, the plot includes the entire range of the scale of the data for item four. The coefficient (\(b_1\)) for group 1 was 0.40, while the coefficient for group 2 was 0.34. The ribbon bands around the plotted slopes indicate the confidence interval for that estimate. In this plot, while the coefficients for each group are not literally equal, the overlapping and parallel slope bands indicate they are not different practically.

\hypertarget{intercepts}{%
\subsubsection{Intercepts}\label{intercepts}}

The item intercepts (\(b_0\)) are plotted on the middle line where they would cross the y-axis at a latent variable score of zero. These are represented by a dot with a set of confidence error bars around the point. The intercept for group 1 was 0.07, while the coefficient for group 2 was 0.03. In this invariant depiction, the overlap in the intercepts is clear, indicating they are not different. You can use \texttt{y\_limits} to zoom in on the graph if these are too small to be distinguishable.

\hypertarget{residuals}{%
\subsubsection{Residuals}\label{residuals}}

Residuals are trickier to plot, as they are the left over error when predicting the observed variables \(\epsilon\). It is tempting to plot this value as the confidence band around the slope, however, that defeats the purpose of understanding that the slopes are estimated separately from the residuals, and both have an associated variability around their parameter estimate. Therefore, residuals are represented in the inset picture at the bottom right of the item invariance plot. The black bars represent the estimated residual for each group (group 1: 0.91, group 2: 1.16). The distributions are plotted to represent the normal spread of values using the standard error of the residuals. The violin plot allows for direct comparison of those residuals and their potential distributions. Note that the placement has nothing to do with the x or y-axis and is designed to always show in the same location, regardless of size/value.

\hypertarget{latent-means}{%
\subsubsection{Latent Means}\label{latent-means}}

The overall impact of differences on the latent means can be found in the right hand visualization. The latent means are calculated by using the \texttt{lavPredict} function and then plotted as overlapping histograms. The vertical colored lines represent the mean for each group, and the spread of the distribution can be examined using the density coloring. Finally, group labels are represented in the figure caption on the bottom. Group 1 is usually the group that is alphabetically first in the data set or whichever group is the first that appears when using the \texttt{levels()} command.

\begin{figure}
\centering
\includegraphics{manuscript_files/figure-latex/invariant-pic-1.pdf}
\caption{\label{fig:invariant-pic}Invariant Model Visualization}
\end{figure}

\hypertarget{graphing-effect-size}{%
\subsubsection{Graphing Effect Size}\label{graphing-effect-size}}

The \(d_{MACS}\) value for item 4 in the invariant model was 0.06, representing a nil or unimportant difference in this manuscript. It is important to note that while Nye et al. (2019) suggests specific sizes for small, medium, and large, each researcher should determine for themselves what effects represent. Figure \ref{fig:small-load-pic} displays the results from the small (\(d_{MACS}\) = 0.12) difference in loadings, while Figure \ref{fig:med-load-pic} displays the results from the medium (\(d_{MACS}\) = 0.43) difference in loadings, and Figure \ref{fig:large-load-pic} shows the large (\(d_{MACS}\) = 0.63) differences. When investigating the slope values, we can clearly see the change in the loading for the second group (the only manipulated variable, although random data set generation may also change intercepts and residuals slightly). At the medium effect size, we see that the confidence bands do not overlap (at the edges), and at the large effect size, we can see a clear separation of two lines. Note that the intercepts in this model are estimated as equal so the loading representation will not literally separate, but the steepness of the lines is the indicator of the difference between the slopes. You can imagine these lines are interpreted like a simple slopes analysis for interactions in regression (Cohen et al., 2003). When simple slopes for interactions are plotted, if they are parallel, there is no interaction, and if they cross, then there is an interaction. Here, we can use this same logic. If they are parallel, there is likely invariance (they are the same), and the further from parallel they become, the larger the effect size for the differences between group loadings.

The latent means in Figure \ref{fig:large-load-pic} do appear to show differences, albeit visually small. The latent means diagram shows the impact of any group differences that aren't constrained, and this image shows the configural model (as the metric model would force them to be equal). In the simulated model, the \emph{only} manipulated parameter is question 4's loading. In real models, the differences may be larger due to other variation found in the parameter estimates. Therefore, once you discover items you believe would make a model ``partially'' invariant, you may wish to estimate that model and graph the item again using the partially invariant model to see only the effect of the non-invariant items. Additionally, consider that we set the scaling of the model to 0. The estimate for the lv mean in the large loading model was group 1: 0.00, and group 2: -0.04, which results in 0.04 difference in group means. The practical implications of this difference will depend on the research and interpretations of the researcher.

\begin{figure}
\centering
\includegraphics{manuscript_files/figure-latex/small-load-pic-1.pdf}
\caption{\label{fig:small-load-pic}Small Loadings Model Visualization}
\end{figure}

\begin{figure}
\centering
\includegraphics{manuscript_files/figure-latex/med-load-pic-1.pdf}
\caption{\label{fig:med-load-pic}Medium Loadings Model Visualization}
\end{figure}

\begin{figure}
\centering
\includegraphics{manuscript_files/figure-latex/large-load-pic-1.pdf}
\caption{\label{fig:large-load-pic}Large Loadings Model Visualization}
\end{figure}

For intercepts, the small (Figure \ref{fig:small-int-pic}), medium (Figure \ref{fig:med-int-pic}), and large (Figure \ref{fig:large-int-pic}) depictions represent \(d_{MACS}\) values of 0.29, 0.52, and 0.76, respectively. Intercept differences can be clearly seen represented by the spacing out of the intercept locations (and thus, the overall line as well). While the changes in intercept do not appear to change the latent means, the caveat to this simulation is that only item four was manipulated. An example is provided below that demonstrates large changes in latent means.

\begin{figure}
\centering
\includegraphics{manuscript_files/figure-latex/small-int-pic-1.pdf}
\caption{\label{fig:small-int-pic}Small Intercepts Model Visualization}
\end{figure}

\begin{figure}
\centering
\includegraphics{manuscript_files/figure-latex/med-int-pic-1.pdf}
\caption{\label{fig:med-int-pic}Medium Intercepts Model Visualization}
\end{figure}

\begin{figure}
\centering
\includegraphics{manuscript_files/figure-latex/large-int-pic-1.pdf}
\caption{\label{fig:large-int-pic}Large Intercepts Model Visualization}
\end{figure}

Last, the effect of the residuals is plotted in small (Figure \ref{fig:small-res-pic}), medium (Figure \ref{fig:med-res-pic}), and large (Figure \ref{fig:large-res-pic}) formats. While \(d_{MACS}\) values are not technically available for the residuals, our models showed 0.20, 0.14, and 0.11, respectively. These differences in values are variable due to the random generation of data sets for each measurement invariance manipulation. At first glance, the differences in the small chart may seem large, because the black lines are not touching, but notice that the distributions overlap, indicating a likely small difference. The medium and large differences better illustrate differences in residuals across groups. Further, the impact of the residuals on the shape of the latent mean distribution can also been seen (and unintentionally, in the first figures as well due to random variation). The impact is due to the standard error of the residuals, as smaller standard errors represent lepokurtic distributions (taller), and larger standard errors represent platykurtic distributions (flatter). The effect size difference of the residuals does not appear to change the effects in the latent means.

\begin{figure}
\centering
\includegraphics{manuscript_files/figure-latex/small-res-pic-1.pdf}
\caption{\label{fig:small-res-pic}Small Residuals Model Visualization}
\end{figure}

\begin{figure}
\centering
\includegraphics{manuscript_files/figure-latex/med-res-pic-1.pdf}
\caption{\label{fig:med-res-pic}Medium Residuals Model Visualization}
\end{figure}

\begin{figure}
\centering
\includegraphics{manuscript_files/figure-latex/large-res-pic-1.pdf}
\caption{\label{fig:large-res-pic}Large Residuals Model Visualization}
\end{figure}

\hypertarget{an-example-analysis}{%
\subsection{An Example Analysis}\label{an-example-analysis}}

Aiena et al. (2014) examined the RS-14 (Wagnild, 2009) exploring the factor structure of the Resiliency Scale in a clinical sample receiving treatment services and a college student sample. Measurement invariance was calculated for differences separately for these samples for gender and race finding a partially invariant models with a few item intercepts or residuals that differed between groups. Aiena et al. (2014) did not compare the clinical to the student sample for measurement invariance, and it is reasonable to expect potential differences in these two populations. This example will demonstrate the procedure for researchers who wish to use partial invariance steps and how to interpret real, messy data.

\small

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load the data}
\FunctionTok{load}\NormalTok{(}\StringTok{"RS14.Rdata"}\NormalTok{)}

\CommentTok{\# build the one{-}factor model }
\NormalTok{model.rs }\OtherTok{\textless{}{-}} \StringTok{"RS =\textasciitilde{} RS1+RS2+RS3+RS4+RS5+RS6+RS7+RS8+RS9+RS10+RS11+RS12+RS13+RS14"}
\CommentTok{\# run the multi{-}group CFA}
\NormalTok{results.rs }\OtherTok{\textless{}{-}} \FunctionTok{mgcfa}\NormalTok{(}\AttributeTok{data =}\NormalTok{ DF, }
                    \AttributeTok{group =} \StringTok{"sample"}\NormalTok{, }
                    \AttributeTok{model =}\NormalTok{ model.rs)}
\end{Highlighting}
\end{Shaded}

\normalsize

\small

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# how to get results in table }
\NormalTok{results.rs}\SpecialCharTok{$}\NormalTok{model\_fit }\SpecialCharTok{\%\textgreater{}\%} 
        \FunctionTok{select}\NormalTok{(model, AIC, BIC, cfi, tli, rmsea, srmr)}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{table}[tbp]

\begin{center}
\begin{threeparttable}

\caption{\label{tab:rs-table}Model Fit for RS-14 Example}

\begin{tabular}{lllllll}
\toprule
Model & AIC & BIC & CFI & TLI & RMSEA & SRMR\\
\midrule
Overall & 126,750.491 & 126,999.816 & 0.934 & 0.923 & 0.094 & 0.033\\
Group 1 & 52,989.421 & 53,196.870 & 0.919 & 0.904 & 0.090 & 0.041\\
Group 2 & 69,128.985 & 69,358.973 & 0.928 & 0.915 & 0.108 & 0.033\\
Configural & 122,118.406 & 122,617.055 & 0.926 & 0.912 & 0.102 & 0.036\\
Metric & 122,144.532 & 122,566.010 & 0.925 & 0.918 & 0.098 & 0.043\\
Scalar & 122,544.109 & 122,888.415 & 0.911 & 0.910 & 0.103 & 0.052\\
Strict & 126,466.241 & 126,727.438 & 0.780 & 0.793 & 0.156 & 0.086\\
\bottomrule
\end{tabular}

\end{threeparttable}
\end{center}

\end{table}

Table \ref{fig:invariant-pic} indicates the results after running the one-factor model. There are several guidelines for assessing assessing a degradation in model fit (Cao \& Liang, 2022; Cheung \& Rensvold, 2002; Counsell et al., 2020; Jin, 2020; Putnick \& Bornstein, 2016) but for the purposes of this illustration \(\Delta\)CFI \textgreater{} .01 will be used. Table \ref{fig:invariant-pic} indicates that fit was degraded when the constraint on equal item intercepts was added. The code below provides an example of testing each item individually by relaxing the constraints and recalculating the CFI. If these Items bring the CFI value back up to \(\Delta\)CFI \textless= .01 from the metric model, then the model would be considering partially invariant at the scalar level. It seems unlikely that the residuals will show invariance, if partial scalar invariance can be found, as the drop in fit is quite large.

\small

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# write out the partial invariance codes for intercepts \textasciitilde{}1}
\NormalTok{partial\_syntax }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(}\FunctionTok{colnames}\NormalTok{(DF)[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{14}\NormalTok{], }\StringTok{"\textasciitilde{}1"}\NormalTok{) }
\NormalTok{partial\_syntax}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{verbatim}
##  [1] "RS1 ~1"  "RS2 ~1"  "RS3 ~1"  "RS4 ~1"  "RS5 ~1"  "RS6 ~1"  "RS7 ~1" 
##  [8] "RS8 ~1"  "RS9 ~1"  "RS10 ~1" "RS11 ~1" "RS12 ~1" "RS13 ~1" "RS14 ~1"
\end{verbatim}

\small

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# create a place to save the CFIs for each item separately}
\NormalTok{CFI\_list  }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(partial\_syntax)}
\FunctionTok{names}\NormalTok{(CFI\_list) }\OtherTok{\textless{}{-}}\NormalTok{ partial\_syntax}
\CommentTok{\# loop over the items and calculate CFI }
\CommentTok{\# with that item freely estimated}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(partial\_syntax))\{}
  
\NormalTok{  temp }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}\AttributeTok{model =}\NormalTok{ model.rs, }
              \AttributeTok{data =}\NormalTok{ DF,}
              \AttributeTok{meanstructure =} \ConstantTok{TRUE}\NormalTok{,}
              \AttributeTok{group =} \StringTok{"sample"}\NormalTok{,}
              \AttributeTok{group.equal =} \FunctionTok{c}\NormalTok{(}\StringTok{"loadings"}\NormalTok{, }\StringTok{"intercepts"}\NormalTok{),}
              \AttributeTok{group.partial =}\NormalTok{ partial\_syntax[i])}
  
\NormalTok{  CFI\_list[i] }\OtherTok{\textless{}{-}} \FunctionTok{fitmeasures}\NormalTok{(temp, }\StringTok{"cfi"}\NormalTok{)}
\NormalTok{\}}
\CommentTok{\# look at the new CFIs}
\NormalTok{CFI\_list}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{verbatim}
##    RS1 ~1    RS2 ~1    RS3 ~1    RS4 ~1    RS5 ~1    RS6 ~1    RS7 ~1    RS8 ~1 
## 0.9116914 0.9129976 0.9117235 0.9111212 0.9126742 0.9133618 0.9139287 0.9111397 
##    RS9 ~1   RS10 ~1   RS11 ~1   RS12 ~1   RS13 ~1   RS14 ~1 
## 0.9119702 0.9118309 0.9110574 0.9112309 0.9112367 0.9112015
\end{verbatim}

The output indicates that RS6 and RS7 are potential items that could be relaxed to improve model fit and create a partial scalar invariant model. The code below show to check the addition of these items, which are added one at a time. You use the \texttt{group.partial} open to ``relax'' or freely estimate that parameter for each group separately. Once that model is saved, you can use the \texttt{tidy} function from \emph{broom} to arrange the estimates from the model, which is used in our plotting function. The \texttt{glance} function will create a tidy dataframe of the fit indices for easy review.

\small

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# run the partially invariant model with group.partial}
\NormalTok{partial.rs }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}\AttributeTok{model =}\NormalTok{ model.rs, }
                  \AttributeTok{data =}\NormalTok{ DF, }
                  \AttributeTok{meanstructure =} \ConstantTok{TRUE}\NormalTok{,}
                  \AttributeTok{group =} \StringTok{"sample"}\NormalTok{, }
                  \AttributeTok{meanstructure =}\NormalTok{ T, }
                  \AttributeTok{group.equal =} \FunctionTok{c}\NormalTok{(}\StringTok{"loadings"}\NormalTok{, }\StringTok{"intercepts"}\NormalTok{),}
                  \AttributeTok{group.partial =} \FunctionTok{c}\NormalTok{(}\StringTok{"RS7\textasciitilde{}1"}\NormalTok{))}

\CommentTok{\# examine the loadings }
\FunctionTok{tidy}\NormalTok{(partial.rs) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(term }\SpecialCharTok{==} \StringTok{"RS7 \textasciitilde{}1 "}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(term, group, estimate, std.error)}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{verbatim}
## # A tibble: 2 x 4
##   term      group estimate std.error
##   <chr>     <int>    <dbl>     <dbl>
## 1 "RS7 ~1 "     1     4.95    0.0580
## 2 "RS7 ~1 "     2     4.49    0.0529
\end{verbatim}

\small

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# examine the fit indices }
\FunctionTok{glance}\NormalTok{(partial.rs) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(AIC, BIC, cfi, tli, rmsea, srmr)}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{verbatim}
## # A tibble: 1 x 6
##       AIC     BIC   cfi   tli rmsea   srmr
##     <dbl>   <dbl> <dbl> <dbl> <dbl>  <dbl>
## 1 122454. 122804. 0.914 0.912 0.102 0.0502
\end{verbatim}

\small

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# effect size model }
\FunctionTok{lavaan\_dmacs}\NormalTok{(partial.rs, }\StringTok{"Clinical"}\NormalTok{)}\SpecialCharTok{$}\NormalTok{DMACS[}\DecValTok{7}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{verbatim}
##      RS7 
## 0.282302
\end{verbatim}

By examining our estimates, we can see that item seven on the RS-14 is estimated at nearly 5 points for the clinical sample, while the student sample has a lower mean around 4.5 points. Generally, students show higher means on the items of the RS14, but when all loadings and other intercepts are constrained to be equal, and this one item is relaxed, this pattern flips so that clinical groups show higher item intercepts. Given the scale is a 1-7 Likert type scale, .5 a point represents a potentially sizable change on the scale. Item seven covers perseverance after hardship, and all items can be found in the user manual for the scale at www.resiliencecenter.com. The effect size from \(d_{DMACS}\) suggests a small to medium effect, 0.28. In this next code section, we repeat this process for the RS6, as the CFI for our model with only RS7 does not achieve the levels of partial invariance for our \(\Delta\)CFI criterion (i.e., \textless= .01 downward change in fit: metric CFI = .925, partial scalar CFI = .914).

\small

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# add the second intercept}
\NormalTok{partial.rs}\FloatTok{.2} \OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}\AttributeTok{model =}\NormalTok{ model.rs, }
                  \AttributeTok{data =}\NormalTok{ DF, }
                  \AttributeTok{meanstructure =} \ConstantTok{TRUE}\NormalTok{,}
                  \AttributeTok{group =} \StringTok{"sample"}\NormalTok{, }
                  \AttributeTok{meanstructure =}\NormalTok{ T, }
                  \AttributeTok{group.equal =} \FunctionTok{c}\NormalTok{(}\StringTok{"loadings"}\NormalTok{, }\StringTok{"intercepts"}\NormalTok{),}
                  \AttributeTok{group.partial =} \FunctionTok{c}\NormalTok{(}\StringTok{"RS7\textasciitilde{}1"}\NormalTok{, }\StringTok{"RS6\textasciitilde{}1"}\NormalTok{))}

\CommentTok{\# examine the loadings }
\FunctionTok{tidy}\NormalTok{(partial.rs}\FloatTok{.2}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(term }\SpecialCharTok{==} \StringTok{"RS6 \textasciitilde{}1 "}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(term, group, estimate, std.error)}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{verbatim}
## # A tibble: 2 x 4
##   term      group estimate std.error
##   <chr>     <int>    <dbl>     <dbl>
## 1 "RS6 ~1 "     1     5.00    0.0605
## 2 "RS6 ~1 "     2     4.54    0.0533
\end{verbatim}

\small

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# examine the fit indices }
\FunctionTok{glance}\NormalTok{(partial.rs}\FloatTok{.2}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(AIC, BIC, cfi, tli, rmsea, srmr)}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{verbatim}
## # A tibble: 1 x 6
##       AIC     BIC   cfi   tli rmsea   srmr
##     <dbl>   <dbl> <dbl> <dbl> <dbl>  <dbl>
## 1 122363. 122719. 0.917 0.915 0.100 0.0488
\end{verbatim}

\small

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# the effect size is }
\FunctionTok{lavaan\_dmacs}\NormalTok{(partial.rs}\FloatTok{.2}\NormalTok{, }\StringTok{"Clinical"}\NormalTok{)}\SpecialCharTok{$}\NormalTok{DMACS[}\DecValTok{6}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{verbatim}
##       RS6 
## 0.2796334
\end{verbatim}

Again, we see about a half-point difference between our clinical and student samples for item 6, which is about drive to achieve. The CFI for this model does meet the requirements for partial invariance, .917. The effect size is approximately the same at 0.28. Last, we can create our images to view the item non-invariance and the latent means in Figures \ref{fig:rs6-img} and \ref{fig:rs7-img}.

\small

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# rebuild the model by constraining item 1 intercept}
\CommentTok{\# allow the latent variable to be estimated}
\NormalTok{model.rs.picture }\OtherTok{\textless{}{-}} \StringTok{"RS =\textasciitilde{} RS1+RS2+RS3+RS4+RS5+RS6+RS7+RS8+RS9+RS10+RS11+RS12+RS13+RS14}
\StringTok{RS\textasciitilde{}1}
\StringTok{RS1\textasciitilde{}0*1"}

\CommentTok{\# rerun the partial invariance model }
\NormalTok{partial.rs.}\FloatTok{2.}\NormalTok{picture }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}\AttributeTok{model =}\NormalTok{ model.rs, }
                  \AttributeTok{data =}\NormalTok{ DF, }
                  \AttributeTok{meanstructure =} \ConstantTok{TRUE}\NormalTok{,}
                  \AttributeTok{group =} \StringTok{"sample"}\NormalTok{, }
                  \AttributeTok{meanstructure =}\NormalTok{ T, }
                  \AttributeTok{group.equal =} \FunctionTok{c}\NormalTok{(}\StringTok{"loadings"}\NormalTok{, }\StringTok{"intercepts"}\NormalTok{),}
                  \AttributeTok{group.partial =} \FunctionTok{c}\NormalTok{(}\StringTok{"RS7\textasciitilde{}1"}\NormalTok{, }\StringTok{"RS6\textasciitilde{}1"}\NormalTok{))}

\CommentTok{\# save the coefficients to use in our picture function }
\NormalTok{partial.coef }\OtherTok{\textless{}{-}} \FunctionTok{tidy}\NormalTok{(partial.rs.}\FloatTok{2.}\NormalTok{picture) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"Scalar"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\normalsize

\normalsize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot the image for RS6}
\FunctionTok{plot\_mgcfa}\NormalTok{(}
  \AttributeTok{data\_coef =}\NormalTok{ partial.coef,}
  \AttributeTok{model\_step =} \StringTok{"Scalar"}\NormalTok{, }
  \AttributeTok{item\_name =} \StringTok{"RS6"}\NormalTok{,}
  \AttributeTok{x\_limits =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{),}
  \AttributeTok{y\_limits =} \FunctionTok{c}\NormalTok{(}\FunctionTok{min}\NormalTok{(DF}\SpecialCharTok{$}\NormalTok{RS7), }\FunctionTok{max}\NormalTok{(DF}\SpecialCharTok{$}\NormalTok{RS7)),}
  \AttributeTok{model\_results =}\NormalTok{ partial.rs.}\FloatTok{2.}\NormalTok{picture, }
  \AttributeTok{ci\_level =}\NormalTok{ .}\DecValTok{95}\NormalTok{,}
  \AttributeTok{lv\_name =} \StringTok{"RS"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{figure}
\centering
\includegraphics{manuscript_files/figure-latex/rs6-img-1.pdf}
\caption{\label{fig:rs6-img}RS6 Item Invariance Visualization}
\end{figure}

\normalsize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot the image for RS7}
\FunctionTok{plot\_mgcfa}\NormalTok{(}
  \AttributeTok{data\_coef =}\NormalTok{ partial.coef,}
  \AttributeTok{model\_step =} \StringTok{"Scalar"}\NormalTok{, }
  \AttributeTok{item\_name =} \StringTok{"RS7"}\NormalTok{,}
  \AttributeTok{x\_limits =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{),}
  \AttributeTok{y\_limits =} \FunctionTok{c}\NormalTok{(}\FunctionTok{min}\NormalTok{(DF}\SpecialCharTok{$}\NormalTok{RS7), }\FunctionTok{max}\NormalTok{(DF}\SpecialCharTok{$}\NormalTok{RS7)),}
  \AttributeTok{model\_results =}\NormalTok{ partial.rs.}\FloatTok{2.}\NormalTok{picture, }
  \AttributeTok{ci\_level =}\NormalTok{ .}\DecValTok{95}\NormalTok{,}
  \AttributeTok{lv\_name =} \StringTok{"RS"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\normalsize

\begin{figure}
\centering
\includegraphics{manuscript_files/figure-latex/rs7-img-1.pdf}
\caption{\label{fig:rs7-img}RS7 Item Invariance Visualization}
\end{figure}

The latent mean is calculated ``separately'' for each group, insomuch as the first group is considered the comparison group, while the second is the difference between groups, like how dummy coded variables in regression are examined. Here we see a difference of 0.72, and students show a higher resiliency score. However, when all other things are held equivalent, the intercepts on items 6 and 7 show higher scores for clinical populations. Additionally, we may see an indication in our student population of a bimodal distribution that may be related to this effect.

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

In this tutorial, we examined how to use multiple tools to examine measurement invariance. Model fit comparisons and statistics can be paired with newly developed effect size measures, and finally a visualization to examine individual items and the overall latent mean scores. This visualization was designed with common graphing elements that researchers often use to display those statistics - intercepts were graphed on the intercept line, slopes were represented as lines of fit, and error terms were represented as distributions. Each component can impact the overall model and the eventual latent mean scores, as shown in the simulations holding all other things equal. Using real data, the effect of two non-invariant item intercepts was examined and visualized. How should one interpret the ``discrepancy'' between the results (these effect visually appear large) from effect sizes (.30 was proposed as small to medium in Nye et al. (2019))?

Effect sizes are notoriously difficult to interpret, which is why we love guidelines, even if Cohen (1990) declared we probably shouldn't use his suggestions. Others have begun to discuss the importance of focusing on effects in the scale of the data and their practical importance (Anvari \& Lakens, 2021; Cumming, 2012). Our interpretation may be that the difference between groups is large, as a 0.72 change on a 7 point scale is approximately 10\% more resiliency for students when compared to the clinical sample. Practically, 10\% in resiliency for an area of the United States (Mississippi) often hit with natural disasters (hurricanes, tornadoes, floods) and high levels of poverty would be very important. Even the smaller difference of .5 point on each individual item could translate into increases in resiliency, and these results may elucidate avenues for further exploration into areas of focus within resiliency, given the items.

What do the results of a study on measurement invariance with these results tell us about replication, generalizability, and validity? If a researcher decides their effects are large, they should likely caution against suggesting that these scores are directly comparable without weighting or other adjustment. Let's consider a scenario wherein the change metric between models picked (i.e., \(\Delta\)CFI, \(\Delta\)RMSEA) indicates a ``significant'' change in model fit. However, if both the effect size and a visual inspection of the invariance indicates a small difference, we may decide to lessen the practical importance of those results, much like ``just significant'' \emph{p}-values with small effect sizes are treated now. Given that the goal of measurement invariance is to compare \emph{estimates}, we should expect some differences across samples due to the nature of sampling and estimation. It may be that many of the published models presented represent these effects - small variations between groups due to sampling error or other small crud - but do not represent a fundamental problem with the measurement or generalizability of the results.

\newpage

\hypertarget{references}{%
\section{References}\label{references}}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-aiena2014}{}}%
Aiena, B. J., Baczwaski, B. J., Schulenberg, S. E., \& Buchanan, E. M. (2014). Measuring Resilience With the RS{\textendash}14: A Tale of Two Samples. \emph{Journal of Personality Assessment}, \emph{97}(3), 291--300. \url{https://doi.org/10.1080/00223891.2014.951445}

\leavevmode\vadjust pre{\hypertarget{ref-akaike1998}{}}%
Akaike, H. (1998). \emph{Information theory and an extension of the maximum likelihood principle} (E. Parzen, K. Tanabe, \& G. Kitagawa, Eds.; pp. 199--213). Springer New York. \url{http://link.springer.com/10.1007/978-1-4612-1694-0_15}

\leavevmode\vadjust pre{\hypertarget{ref-anvari2021}{}}%
Anvari, F., \& Lakens, D. (2021). Using anchor-based methods to determine the smallest effect size of interest. \emph{Journal of Experimental Social Psychology}, \emph{96}, 104159. \url{https://doi.org/10.1016/j.jesp.2021.104159}

\leavevmode\vadjust pre{\hypertarget{ref-barry2014}{}}%
Barry, A. E., Chaney, B., Piazza-Gardner, A. K., \& Chavarria, E. A. (2014). Validity and Reliability Reporting Practices in the Field of Health Education and Behavior: A Review of Seven Journals. \emph{Health Education \& Behavior}, \emph{41}(1), 12--18. \url{https://doi.org/10.1177/1090198113483139}

\leavevmode\vadjust pre{\hypertarget{ref-beaujean2014}{}}%
Beaujean, A. A. (2014). \emph{Latent variable modeling using r: A step by step guide}. Routledge/Taylor \& Francis Group.

\leavevmode\vadjust pre{\hypertarget{ref-bentler1990}{}}%
Bentler, P. M. (1990). Comparative fit indexes in structural models. \emph{Psychological Bulletin}, \emph{107}(2), 238--246. \url{https://doi.org/10.1037/0033-2909.107.2.238}

\leavevmode\vadjust pre{\hypertarget{ref-bentler1995}{}}%
Bentler, P. M. (1995). \emph{EQS structural equations program manual}.

\leavevmode\vadjust pre{\hypertarget{ref-boker2011}{}}%
Boker, S., Neale, M., Maes, H., Wilde, M., Spiegel, M., Brick, T., Spies, J., Estabrook, R., Kenny, S., Bates, T., Mehta, P., \& Fox, J. (2011). OpenMx: An Open Source Extended Structural Equation Modeling Framework. \emph{Psychometrika}, \emph{76}(2), 306--317. \url{https://doi.org/10.1007/s11336-010-9200-6}

\leavevmode\vadjust pre{\hypertarget{ref-brown2015}{}}%
Brown, T. A. (2015). \emph{Confirmatory factor analysis for applied research} (Second edition). The Guilford Press.

\leavevmode\vadjust pre{\hypertarget{ref-byrne2001}{}}%
Byrne, B. M. (2001). Structural Equation Modeling With AMOS, EQS, and LISREL: Comparative Approaches to Testing for the Factorial Validity of a Measuring Instrument. \emph{International Journal of Testing}, \emph{1}(1), 55--86. \url{https://doi.org/10.1207/S15327574IJT0101_4}

\leavevmode\vadjust pre{\hypertarget{ref-byrne1989}{}}%
Byrne, B. M., Shavelson, R. J., \& Muthén, B. (1989). Testing for the equivalence of factor covariance and mean structures: The issue of partial measurement invariance. \emph{Psychological Bulletin}, \emph{105}(3), 456--466. \url{https://doi.org/10.1037/0033-2909.105.3.456}

\leavevmode\vadjust pre{\hypertarget{ref-cao2022}{}}%
Cao, C., \& Liang, X. (2022). The impact of model size on the sensitivity of fit measures in measurement invariance testing. \emph{Structural Equation Modeling: A Multidisciplinary Journal}, \emph{29}(5), 744--754. \url{https://doi.org/10.1080/10705511.2022.2056893}

\leavevmode\vadjust pre{\hypertarget{ref-cheung2002}{}}%
Cheung, G. W., \& Rensvold, R. B. (2002). Evaluating Goodness-of-Fit Indexes for Testing Measurement Invariance. \emph{Structural Equation Modeling: A Multidisciplinary Journal}, \emph{9}(2), 233--255. \url{https://doi.org/10.1207/s15328007sem0902_5}

\leavevmode\vadjust pre{\hypertarget{ref-chorpita2000}{}}%
Chorpita, B. F., Yim, L., Moffitt, C., Umemoto, L. A., \& Francis, S. E. (2000). Assessment of symptoms of DSM-IV anxiety and depression in children: a revised child anxiety and depression scale. \emph{Behaviour Research and Therapy}, \emph{38}(8), 835--855. \url{https://doi.org/10.1016/S0005-7967(99)00130-8}

\leavevmode\vadjust pre{\hypertarget{ref-cohen1990}{}}%
Cohen, J. (1990). Things I have learned (so far). \emph{American Psychologist}, \emph{45}(12), 1304--1312. \url{https://doi.org/10.1037/0003-066X.45.12.1304}

\leavevmode\vadjust pre{\hypertarget{ref-cohen2003}{}}%
Cohen, J., Cohen, P., West, S. G., \& Aiken, L. (2003). \emph{Applied multiple regression / correlation analysis for the behavioral sciences} (3rd ed.). Lawrence Erlbaum Associates.

\leavevmode\vadjust pre{\hypertarget{ref-counsell2020}{}}%
Counsell, A., Cribbie, R. A., \& Flora, D. B. (2020). Evaluating equivalence testing methods for measurement invariance. \emph{Multivariate Behavioral Research}, \emph{55}(2), 312--328. \url{https://doi.org/10.1080/00273171.2019.1633617}

\leavevmode\vadjust pre{\hypertarget{ref-cumming2012}{}}%
Cumming, G. (2012). \emph{Understanding the new statistics: Effect sizes, confidence intervals, and meta-analysis}. Routledge.

\leavevmode\vadjust pre{\hypertarget{ref-devellis2022}{}}%
DeVellis, R. F., \& Thorpe, C. T. (2022). \emph{Scale development: Theory and applications} (Fifth edition). SAGE Publications, Inc.

\leavevmode\vadjust pre{\hypertarget{ref-dueber2023}{}}%
Dueber, D. (2023). \emph{Dmacs}. \url{https://github.com/ddueber/dmacs}

\leavevmode\vadjust pre{\hypertarget{ref-flake2020}{}}%
Flake, J. K., \& Fried, E. I. (2020). Measurement Schmeasurement: Questionable Measurement Practices and How to Avoid Them. \emph{Advances in Methods and Practices in Psychological Science}, \emph{3}(4), 456--465. \url{https://doi.org/10.1177/2515245920952393}

\leavevmode\vadjust pre{\hypertarget{ref-jin2020}{}}%
Jin, Y. (2020). A note on the cutoff values of alternative fit indices to evaluate measurement invariance for ESEM models. \emph{International Journal of Behavioral Development}, \emph{44}(2), 166--174. \url{https://doi.org/10.1177/0165025419866911}

\leavevmode\vadjust pre{\hypertarget{ref-juxf6reskog1971}{}}%
Jöreskog, K. G. (1971). Simultaneous factor analysis in several populations. \emph{Psychometrika}, \emph{36}(4), 409--426. \url{https://doi.org/10.1007/BF02291366}

\leavevmode\vadjust pre{\hypertarget{ref-juxf6reskog2001}{}}%
Jöreskog, K. G., \& Sörbom, D. (2001). \emph{LISREL 8: user's reference guide} (2. ed., updated to LISREL 8). SSI Scientific Software Internat.

\leavevmode\vadjust pre{\hypertarget{ref-kline2016}{}}%
Kline, R. B. (2016). \emph{Principles and practice of structural equation modeling} (Fourth edition). The Guilford Press.

\leavevmode\vadjust pre{\hypertarget{ref-lakens2017}{}}%
Lakens, D. (2017). Equivalence Tests. \emph{Social Psychological and Personality Science}, \emph{8}(4), 355--362. \url{https://doi.org/10.1177/1948550617697177}

\leavevmode\vadjust pre{\hypertarget{ref-makel2014}{}}%
Makel, M. C., \& Plucker, J. A. (2014). Facts Are More Important Than Novelty: Replication in the Education Sciences. \emph{Educational Researcher}, \emph{43}(6), 304--316. \url{https://doi.org/10.3102/0013189X14545513}

\leavevmode\vadjust pre{\hypertarget{ref-makel2012}{}}%
Makel, M. C., Plucker, J. A., \& Hegarty, B. (2012). Replications in Psychology Research: How Often Do They Really Occur? \emph{Perspectives on Psychological Science}, \emph{7}(6), 537--542. \url{https://doi.org/10.1177/1745691612460688}

\leavevmode\vadjust pre{\hypertarget{ref-marsh2004}{}}%
Marsh, H. W., Hau, K.-T., \& Wen, Z. (2004). In search of golden rules: Comment on hypothesis-testing approaches to setting cutoff values for fit indexes and dangers in overgeneralizing hu and bentler's (1999) findings. \emph{Structural Equation Modeling: A Multidisciplinary Journal}, \emph{11}(3), 320--341. \url{https://doi.org/10.1207/s15328007sem1103_2}

\leavevmode\vadjust pre{\hypertarget{ref-meade2008}{}}%
Meade, A. W., Johnson, E. C., \& Braddy, P. W. (2008). Power and sensitivity of alternative fit indices in tests of measurement invariance. \emph{Journal of Applied Psychology}, \emph{93}(3), 568--592. \url{https://doi.org/10.1037/0021-9010.93.3.568}

\leavevmode\vadjust pre{\hypertarget{ref-meredith1993}{}}%
Meredith, W. (1993). Measurement invariance, factor analysis and factorial invariance. \emph{Psychometrika}, \emph{58}(4), 525--543. \url{https://doi.org/10.1007/BF02294825}

\leavevmode\vadjust pre{\hypertarget{ref-nelson2018}{}}%
Nelson, L. D., Simmons, J., \& Simonsohn, U. (2018). Psychology's renaissance. \emph{Annual Review of Psychology}, \emph{69}(1), 511--534. \url{https://doi.org/10.1146/annurev-psych-122216-011836}

\leavevmode\vadjust pre{\hypertarget{ref-nye2019}{}}%
Nye, C. D., Bradburn, J., Olenick, J., Bialko, C., \& Drasgow, F. (2019). How Big Are My Effects? Examining the Magnitude of Effect Sizes in Studies of Measurement Equivalence. \emph{Organizational Research Methods}, \emph{22}(3), 678--709. \url{https://doi.org/10.1177/1094428118761122}

\leavevmode\vadjust pre{\hypertarget{ref-nye2011}{}}%
Nye, C. D., \& Drasgow, F. (2011). Effect size indices for analyses of measurement equivalence: Understanding the practical importance of differences between groups. \emph{Journal of Applied Psychology}, \emph{96}(5), 966--980. \url{https://doi.org/10.1037/a0022955}

\leavevmode\vadjust pre{\hypertarget{ref-putnick2016}{}}%
Putnick, D. L., \& Bornstein, M. H. (2016). Measurement invariance conventions and reporting: The state of the art and future directions for psychological research. \emph{Developmental Review}, \emph{41}, 71--90. \url{https://doi.org/10.1016/j.dr.2016.06.004}

\leavevmode\vadjust pre{\hypertarget{ref-robinson2023}{}}%
Robinson, D., Hayes, A., Couch {[}aut, S., cre, Software, P., PBC, Patil, I., Chiu, D., Gomez, M., Demeshev, B., Menne, D., Nutter, B., Johnston, L., Bolker, B., Briatte, F., Arnold, J., Gabry, J., Selzer, L., Simpson, G., \ldots{} Reinhart, A. (2023). \emph{Broom: Convert statistical objects into tidy tibbles}. \url{https://CRAN.R-project.org/package=broom}

\leavevmode\vadjust pre{\hypertarget{ref-rosseel2012}{}}%
Rosseel, Y. (2012). Lavaan: An r package for structural equation modeling. \emph{Journal of Statistical Software}, \emph{48}(1), 1--36. \url{https://doi.org/10.18637/jss.v048.i02}

\leavevmode\vadjust pre{\hypertarget{ref-schwarz1978}{}}%
Schwarz, G. (1978). Estimating the dimension of a model. \emph{The Annals of Statistics}, \emph{6}(2), 461--464. \url{https://www.jstor.org/stable/2958889}

\leavevmode\vadjust pre{\hypertarget{ref-shadish2001}{}}%
Shadish, W. R., Cook, T. D., \& Campbell, D. T. (2001). \emph{Experimental and quasi-experimental designs for generalized causal inference}. Houghton Mifflin.

\leavevmode\vadjust pre{\hypertarget{ref-suxf6rbom1978}{}}%
Sörbom, D. (1978). An alternative to the methodology for analysis of covariance. \emph{Psychometrika}, \emph{43}(3), 381--396. \url{https://doi.org/10.1007/BF02293647}

\leavevmode\vadjust pre{\hypertarget{ref-stark2006}{}}%
Stark, S., Chernyshenko, O. S., \& Drasgow, F. (2006). Detecting differential item functioning with confirmatory factor analysis and item response theory: Toward a unified strategy. \emph{Journal of Applied Psychology}, \emph{91}(6), 1292--1306. \url{https://doi.org/10.1037/0021-9010.91.6.1292}

\leavevmode\vadjust pre{\hypertarget{ref-steiger1990}{}}%
Steiger, J. H. (1990). Structural model evaluation and modification: An interval estimation approach. \emph{Multivariate Behavioral Research}, \emph{25}(2), 173--180. \url{https://doi.org/10.1207/s15327906mbr2502_4}

\leavevmode\vadjust pre{\hypertarget{ref-tay2015}{}}%
Tay, L., Meade, A. W., \& Cao, M. (2015). An Overview and Practical Guide to IRT Measurement Equivalence Analysis. \emph{Organizational Research Methods}, \emph{18}(1), 3--46. \url{https://doi.org/10.1177/1094428114553062}

\leavevmode\vadjust pre{\hypertarget{ref-thompson1996}{}}%
Thompson, B., \& Daniel, L. G. (1996). Factor Analytic Evidence for the Construct Validity of Scores: A Historical Overview and Some Guidelines. \emph{Educational and Psychological Measurement}, \emph{56}(2), 197--208. \url{https://doi.org/10.1177/0013164496056002001}

\leavevmode\vadjust pre{\hypertarget{ref-trent2013}{}}%
Trent, L. R., Buchanan, E., Ebesutani, C., Ale, C. M., Heiden, L., Hight, T. L., Damon, J. D., \& Young, J. (2013). A measurement invariance examination of the revised child anxiety and depression scale in a southern sample: Differential item functioning between african american and caucasian youth. \emph{Assessment}, \emph{20}(2), 175--187. \url{https://doi.org/10.1177/1073191112450907}

\leavevmode\vadjust pre{\hypertarget{ref-tucker1973}{}}%
Tucker, L. R., \& Lewis, C. (1973). A reliability coefficient for maximum likelihood factor analysis. \emph{Psychometrika}, \emph{38}(1), 1--10. \url{https://doi.org/10.1007/BF02291170}

\leavevmode\vadjust pre{\hypertarget{ref-vandeschoot2015}{}}%
Van De Schoot, R., Schmidt, P., De Beuckelaer, A., Lek, K., \& Zondervan-Zwijnenburg, M. (2015). Editorial: Measurement invariance. \emph{Frontiers in Psychology}, \emph{6}. \url{https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01064}

\leavevmode\vadjust pre{\hypertarget{ref-vazire2022}{}}%
Vazire, S., Schiavone, S. R., \& Bottesini, J. G. (2022). Credibility Beyond Replicability: Improving the Four Validities in Psychological Science. \emph{Current Directions in Psychological Science}, \emph{31}(2), 162--168. \url{https://doi.org/10.1177/09637214211067779}

\leavevmode\vadjust pre{\hypertarget{ref-wagnild2009}{}}%
Wagnild, G. (2009). A review of the resilience scale. \emph{Journal of Nursing Measurement}, \emph{17}(2), 105--113. \url{https://doi.org/10.1891/1061-3749.17.2.105}

\leavevmode\vadjust pre{\hypertarget{ref-weidman2017}{}}%
Weidman, A. C., Steckler, C. M., \& Tracy, J. L. (2017). The jingle and jangle of emotion assessment: Imprecise measurement, casual scale usage, and conceptual fuzziness in emotion research. \emph{Emotion}, \emph{17}(2), 267--295. \url{https://doi.org/10.1037/emo0000226}

\leavevmode\vadjust pre{\hypertarget{ref-R-ggplot2}{}}%
Wickham, H. (2016). \emph{ggplot2: Elegant graphics for data analysis}. Springer-Verlag New York. \url{https://ggplot2.tidyverse.org}

\leavevmode\vadjust pre{\hypertarget{ref-wilke2020}{}}%
Wilke, C. O. (2020). \emph{Cowplot: Streamlined plot theme and plot annotations for 'ggplot2'}. \url{https://CRAN.R-project.org/package=cowplot}

\leavevmode\vadjust pre{\hypertarget{ref-zwaan2018}{}}%
Zwaan, R. A., Etz, A., Lucas, R. E., \& Donnellan, M. B. (2018). Making replication mainstream. \emph{Behavioral and Brain Sciences}, \emph{41}, e120. \url{https://doi.org/10.1017/S0140525X17001972}

\end{CSLReferences}

\newpage

\hypertarget{appendix}{%
\section{Appendix}\label{appendix}}

\hypertarget{mgcfa-convenience-function}{%
\subsection{MGCFA Convenience Function}\label{mgcfa-convenience-function}}

Please note that any partial invariance is not automatically included in this function. This function returns a list with all model summaries, the model coefficients in a tidy dataframe, and the model fit statistics in a tidy dataframe. You will need the libraries listed below for this function to work properly.

\small

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(lavaan)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(broom)}
\CommentTok{\# CFA function}
\NormalTok{mgcfa }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data, group, model)\{}
  
\NormalTok{  group\_names }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(data[ , group])}
\NormalTok{  data}\SpecialCharTok{$}\NormalTok{group }\OtherTok{\textless{}{-}}\NormalTok{ data[ , group]}
  
\NormalTok{  model.overall }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}\AttributeTok{model =}\NormalTok{ model, }\AttributeTok{data =}\NormalTok{ data, }
                       \AttributeTok{meanstructure =}\NormalTok{ T)}
\NormalTok{  model.group1 }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}\AttributeTok{model =}\NormalTok{ model, }
                      \AttributeTok{data =} \FunctionTok{subset}\NormalTok{(data, group }\SpecialCharTok{==}\NormalTok{ group\_names[}\DecValTok{1}\NormalTok{]),}
                      \AttributeTok{meanstructure =}\NormalTok{ T)}
\NormalTok{  model.group2 }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}\AttributeTok{model =}\NormalTok{ model, }
                      \AttributeTok{data =} \FunctionTok{subset}\NormalTok{(data, group }\SpecialCharTok{==}\NormalTok{ group\_names[}\DecValTok{2}\NormalTok{]),}
                      \AttributeTok{meanstructure =}\NormalTok{ T)}
\NormalTok{  model.configural }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}\AttributeTok{model =}\NormalTok{ model, }\AttributeTok{data =}\NormalTok{ data, }
                          \AttributeTok{group =}\NormalTok{ group, }\AttributeTok{meanstructure =}\NormalTok{ T)}
\NormalTok{  model.metric }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}\AttributeTok{model =}\NormalTok{ model, }\AttributeTok{data =}\NormalTok{ data, }
                      \AttributeTok{group =}\NormalTok{ group, }\AttributeTok{meanstructure =}\NormalTok{ T,}
                      \AttributeTok{group.equal =} \StringTok{"loadings"}\NormalTok{)}
\NormalTok{  model.scalar }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}\AttributeTok{model =}\NormalTok{ model, }\AttributeTok{data =}\NormalTok{ data, }
                      \AttributeTok{group =}\NormalTok{ group, }\AttributeTok{meanstructure =}\NormalTok{ T, }
                      \AttributeTok{group.equal =} \FunctionTok{c}\NormalTok{(}\StringTok{"loadings"}\NormalTok{, }\StringTok{"intercepts"}\NormalTok{))}
\NormalTok{  model.strict }\OtherTok{\textless{}{-}} \FunctionTok{cfa}\NormalTok{(}\AttributeTok{model =}\NormalTok{ model, }\AttributeTok{data =}\NormalTok{ data, }
                      \AttributeTok{group =}\NormalTok{ group, }\AttributeTok{meanstructure =}\NormalTok{ T, }
                      \AttributeTok{group.equal =}  \FunctionTok{c}\NormalTok{(}\StringTok{"loadings"}\NormalTok{, }\StringTok{"intercepts"}\NormalTok{, }\StringTok{"residuals"}\NormalTok{))}
  
\NormalTok{  model\_coef }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(}
    \FunctionTok{tidy}\NormalTok{(model.overall, }\AttributeTok{conf.level =}\NormalTok{ .}\DecValTok{95}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
      \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"Overall"}\NormalTok{), }
    \FunctionTok{tidy}\NormalTok{(model.group1, }\AttributeTok{conf.level =}\NormalTok{ .}\DecValTok{95}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
      \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"Group 1"}\NormalTok{), }
    \FunctionTok{tidy}\NormalTok{(model.group2, }\AttributeTok{conf.level =}\NormalTok{ .}\DecValTok{95}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
      \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"Group 2"}\NormalTok{), }
    \FunctionTok{tidy}\NormalTok{(model.configural, }\AttributeTok{conf.level =}\NormalTok{ .}\DecValTok{95}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
      \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"Configural"}\NormalTok{), }
    \FunctionTok{tidy}\NormalTok{(model.metric, }\AttributeTok{conf.level =}\NormalTok{ .}\DecValTok{95}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
      \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"Metric"}\NormalTok{), }
    \FunctionTok{tidy}\NormalTok{(model.scalar, }\AttributeTok{conf.level =}\NormalTok{ .}\DecValTok{95}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
      \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"Scalar"}\NormalTok{), }
    \FunctionTok{tidy}\NormalTok{(model.strict, }\AttributeTok{conf.level =}\NormalTok{ .}\DecValTok{95}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
      \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"Strict"}\NormalTok{)}
\NormalTok{  )}
    
\NormalTok{  model\_fit }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(}
    \FunctionTok{glance}\NormalTok{(model.overall) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"Overall"}\NormalTok{), }
    \FunctionTok{glance}\NormalTok{(model.group1) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"Group 1"}\NormalTok{), }
    \FunctionTok{glance}\NormalTok{(model.group2) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"Group 2"}\NormalTok{), }
    \FunctionTok{glance}\NormalTok{(model.configural) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"Configural"}\NormalTok{), }
    \FunctionTok{glance}\NormalTok{(model.metric) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"Metric"}\NormalTok{), }
    \FunctionTok{glance}\NormalTok{(model.scalar) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"Scalar"}\NormalTok{), }
    \FunctionTok{glance}\NormalTok{(model.strict) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"Strict"}\NormalTok{)}
\NormalTok{    )}
  
  \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}
    \StringTok{"model\_coef"} \OtherTok{=}\NormalTok{ model\_coef,}
    \StringTok{"model\_fit"} \OtherTok{=}\NormalTok{ model\_fit,}
    \StringTok{"model.overall"} \OtherTok{=}\NormalTok{ model.overall,}
    \StringTok{"model.group1"} \OtherTok{=}\NormalTok{ model.group1,}
    \StringTok{"model.group2"} \OtherTok{=}\NormalTok{ model.group2,}
    \StringTok{"model.configural"} \OtherTok{=}\NormalTok{ model.configural,}
    \StringTok{"model.metric"} \OtherTok{=}\NormalTok{ model.metric,}
    \StringTok{"model.scalar"} \OtherTok{=}\NormalTok{ model.scalar,}
    \StringTok{"model.strict"} \OtherTok{=}\NormalTok{ model.strict}
\NormalTok{  ))}
  
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\normalsize

\hypertarget{measurement-invariance-plot-function}{%
\subsection{Measurement Invariance Plot Function}\label{measurement-invariance-plot-function}}

This function creates the plots shown in the manuscript. You will need the libraries listed for this function to work. Plots may be modified to rearrange for those who are familiar with \texttt{ggplot2}. Please note that the function assumes you will use the outputs from the previous \texttt{mgcfa} function or a tidy dataframe that includes the coefficients from the model with a column \texttt{model} that indicates which step of the MGCFA you are wanting to plot. If you have more than two groups, you should first filter the dataframe model coefficient outputs to only include to the two groups you want to compare. This code does not plot more than two groups (although, it could be modified for this, but the assumption here is that you only have two, as this is how you would normally proceed in a MGCFA using pairwise comparisons to find where the invariance occurs).

\small

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(cowplot)}
\FunctionTok{library}\NormalTok{(lavaan)}
\CommentTok{\# devtools::install\_github("psyteachr/introdataviz")}
\FunctionTok{library}\NormalTok{(introdataviz)}
\CommentTok{\# Plot MI MGCFA}
\NormalTok{plot\_mgcfa }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data\_coef, }\CommentTok{\# output from model\_coef}
\NormalTok{                       model\_step, }\CommentTok{\# which model}
\NormalTok{                       item\_name, }\CommentTok{\# name of observed item}
                       \AttributeTok{x\_limits =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{), }\CommentTok{\# LV limits to graph}
\NormalTok{                       y\_limits, }\CommentTok{\# Y min and max in data }
\NormalTok{                       ci\_level, }\CommentTok{\# what ci do you want}
\NormalTok{                       model\_results, }\CommentTok{\# what model results do you want }
\NormalTok{                       lv\_name }\CommentTok{\# which latent is the observed variable on}
\NormalTok{                       )\{}
  
  \CommentTok{\# calculate cutoff}
\NormalTok{  cutoff }\OtherTok{\textless{}{-}} \FunctionTok{qt}\NormalTok{(}\AttributeTok{p =}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{ci\_level)}\SpecialCharTok{/}\DecValTok{2}\NormalTok{, }
               \AttributeTok{df =} \FunctionTok{sum}\NormalTok{(}\FunctionTok{unlist}\NormalTok{(model\_results}\SpecialCharTok{@}\NormalTok{Data}\SpecialCharTok{@}\NormalTok{nobs)), }
               \AttributeTok{lower.tail =}\NormalTok{ F)}
  
  \CommentTok{\# get group variable}
\NormalTok{  group\_var }\OtherTok{\textless{}{-}}\NormalTok{ model\_results}\SpecialCharTok{@}\NormalTok{Data}\SpecialCharTok{@}\NormalTok{group}
\NormalTok{  group\_labels }\OtherTok{\textless{}{-}}\NormalTok{ model\_results}\SpecialCharTok{@}\NormalTok{Data}\SpecialCharTok{@}\NormalTok{group.label}
  
  \CommentTok{\# first get the data}
\NormalTok{  graph.data }\OtherTok{\textless{}{-}}\NormalTok{ data\_coef }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# put in tidy coefficients}
  \FunctionTok{filter}\NormalTok{(model }\SpecialCharTok{==}\NormalTok{ model\_step) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# pick a model}
  \FunctionTok{filter}\NormalTok{(}\FunctionTok{grepl}\NormalTok{(item\_name, term)) }\SpecialCharTok{\%\textgreater{}\%}  \CommentTok{\# pick a question}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{group =} \FunctionTok{factor}\NormalTok{(group, }\AttributeTok{levels =} \FunctionTok{names}\NormalTok{(}\FunctionTok{table}\NormalTok{(data\_coef}\SpecialCharTok{$}\NormalTok{group)), }
                        \AttributeTok{labels =}\NormalTok{ group\_labels)) }
  
  \CommentTok{\# make ribbon data y = slope*x + intercept for ci for slopes }
\NormalTok{  ribbondata }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(}
    \FunctionTok{data.frame}\NormalTok{(}
    \AttributeTok{x =} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from =}\NormalTok{ x\_limits[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{,  }
            \AttributeTok{to =}\NormalTok{ x\_limits[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }
            \AttributeTok{by =}\NormalTok{ .}\DecValTok{05}\NormalTok{), }
    \AttributeTok{group =} \FunctionTok{unique}\NormalTok{(graph.data}\SpecialCharTok{$}\NormalTok{group)[}\DecValTok{1}\NormalTok{]}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ (graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"=\textasciitilde{}"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
                 \FunctionTok{slice\_head}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(estimate) }\SpecialCharTok{*}\NormalTok{ x) }\SpecialCharTok{{-}} 
\NormalTok{             (cutoff}\SpecialCharTok{*}\NormalTok{graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"=\textasciitilde{}"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
                    \FunctionTok{slice\_head}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(std.error)) }\SpecialCharTok{+}
\NormalTok{             graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"\textasciitilde{}1"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
                 \FunctionTok{slice\_head}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(estimate), }
           \AttributeTok{ymax =}\NormalTok{ (graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"=\textasciitilde{}"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
                 \FunctionTok{slice\_head}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(estimate) }\SpecialCharTok{*}\NormalTok{ x) }\SpecialCharTok{+} 
\NormalTok{             (cutoff}\SpecialCharTok{*}\NormalTok{graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"=\textasciitilde{}"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
                    \FunctionTok{slice\_head}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(std.error)) }\SpecialCharTok{+}
\NormalTok{             graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"\textasciitilde{}1"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
                 \FunctionTok{slice\_head}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(estimate)), }
    \FunctionTok{data.frame}\NormalTok{(}
      \AttributeTok{x =} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from =}\NormalTok{ x\_limits[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{,  }
              \AttributeTok{to =}\NormalTok{ x\_limits[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{+} \DecValTok{1}\NormalTok{, }
              \AttributeTok{by =}\NormalTok{ .}\DecValTok{05}\NormalTok{), }
      \AttributeTok{group =} \FunctionTok{unique}\NormalTok{(graph.data}\SpecialCharTok{$}\NormalTok{group)[}\DecValTok{2}\NormalTok{]}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%} 
      \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ (graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"=\textasciitilde{}"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
                   \FunctionTok{slice\_tail}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(estimate) }\SpecialCharTok{*}\NormalTok{ x) }\SpecialCharTok{{-}} 
\NormalTok{               (cutoff}\SpecialCharTok{*}\NormalTok{graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"=\textasciitilde{}"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
                      \FunctionTok{slice\_tail}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(std.error)) }\SpecialCharTok{+}
\NormalTok{               graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"\textasciitilde{}1"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
                   \FunctionTok{slice\_tail}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(estimate), }
             \AttributeTok{ymax =}\NormalTok{ (graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"=\textasciitilde{}"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
                   \FunctionTok{slice\_tail}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(estimate) }\SpecialCharTok{*}\NormalTok{ x) }\SpecialCharTok{+} 
\NormalTok{               (cutoff}\SpecialCharTok{*}\NormalTok{graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"=\textasciitilde{}"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
                      \FunctionTok{slice\_tail}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(std.error)) }\SpecialCharTok{+}
\NormalTok{               graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"\textasciitilde{}1"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
                   \FunctionTok{slice\_tail}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(estimate))}
\NormalTok{  )}
  
  \CommentTok{\# make point data to draw on the intercepts }
\NormalTok{  pointdata }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{),}
  \AttributeTok{y =}\NormalTok{ graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"\textasciitilde{}1"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(estimate), }
  \AttributeTok{group =}\NormalTok{ graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"\textasciitilde{}1"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(group),}
  \AttributeTok{ymin =}\NormalTok{ graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"\textasciitilde{}1"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(estimate) }\SpecialCharTok{{-}} 
\NormalTok{    cutoff }\SpecialCharTok{*}\NormalTok{ graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"\textasciitilde{}1"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(std.error), }
  \AttributeTok{ymax =}\NormalTok{ graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"\textasciitilde{}1"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(estimate) }\SpecialCharTok{+} 
\NormalTok{    cutoff }\SpecialCharTok{*}\NormalTok{ graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"\textasciitilde{}1"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(std.error)}
\NormalTok{  )}
  
  \CommentTok{\# make the line data to draw on the slopes}
\NormalTok{  linedata }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{slope =}\NormalTok{ graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"=\textasciitilde{}"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(estimate), }
  \AttributeTok{intercept =}\NormalTok{ graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"\textasciitilde{}1"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(estimate), }
  \AttributeTok{group =}\NormalTok{ graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"\textasciitilde{}1"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(group)}
\NormalTok{  )}
  
  \CommentTok{\# make the distributions for the residuals }
\NormalTok{  violindata }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{y =} \FunctionTok{c}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{1000}\NormalTok{, }
            \AttributeTok{mean =}\NormalTok{ graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"\textasciitilde{}\textasciitilde{}"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
              \FunctionTok{slice\_head}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(estimate), }
            \AttributeTok{sd =}\NormalTok{ graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"\textasciitilde{}\textasciitilde{}"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
              \FunctionTok{slice\_head}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(std.error)), }
        \FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \DecValTok{1000}\NormalTok{, }
            \AttributeTok{mean =}\NormalTok{ graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"\textasciitilde{}\textasciitilde{}"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
              \FunctionTok{slice\_tail}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(estimate), }
            \AttributeTok{sd =}\NormalTok{ graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"\textasciitilde{}\textasciitilde{}"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
              \FunctionTok{slice\_tail}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(std.error))),}
  \AttributeTok{group =} \FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"\textasciitilde{}\textasciitilde{}"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
              \FunctionTok{slice\_head}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(group), }\DecValTok{1000}\NormalTok{),}
            \FunctionTok{rep}\NormalTok{(graph.data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(op }\SpecialCharTok{==} \StringTok{"\textasciitilde{}\textasciitilde{}"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
              \FunctionTok{slice\_tail}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{pull}\NormalTok{(group), }\DecValTok{1000}\NormalTok{)), }
  \AttributeTok{x =} \DecValTok{1}
\NormalTok{  )}
  
  \CommentTok{\# make the latent mean data for right panel}
\NormalTok{  latent\_means }\OtherTok{\textless{}{-}} \FunctionTok{lavPredict}\NormalTok{(model\_results, }
                               \AttributeTok{type =} \StringTok{"lv"}\NormalTok{, }
                               \AttributeTok{label =} \ConstantTok{TRUE}\NormalTok{,}
                               \AttributeTok{assemble =} \ConstantTok{TRUE}\NormalTok{, }
                               \AttributeTok{append.data =} \ConstantTok{TRUE}\NormalTok{)}
  
\NormalTok{  latent\_means}\SpecialCharTok{$}\NormalTok{lv }\OtherTok{\textless{}{-}}\NormalTok{ latent\_means[ , lv\_name]}
\NormalTok{  latent\_means}\SpecialCharTok{$}\NormalTok{group }\OtherTok{\textless{}{-}}\NormalTok{ latent\_means[ , group\_var]}
  
  \CommentTok{\# make a plot of the variance}
\NormalTok{  variance\_plot }\OtherTok{\textless{}{-}} 
  \FunctionTok{ggplot}\NormalTok{(violindata, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \DecValTok{1}\NormalTok{, }\AttributeTok{y =}\NormalTok{ y, }\AttributeTok{color =}\NormalTok{ group, }\AttributeTok{fill =}\NormalTok{ group)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_split\_violin}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{theme\_void}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{stat\_summary}\NormalTok{(}\AttributeTok{fun =} \StringTok{"mean"}\NormalTok{,}
               \AttributeTok{geom =} \StringTok{"crossbar"}\NormalTok{, }
               \AttributeTok{width =} \FloatTok{0.5}\NormalTok{,}
               \AttributeTok{colour =} \StringTok{"black"}\NormalTok{)}
  
  \CommentTok{\# make the plot with intercepts and slopes}
\NormalTok{  intercept\_plot }\OtherTok{\textless{}{-}} 
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+} 
  \CommentTok{\# basic set up}
  \FunctionTok{theme\_classic}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Latent Variable"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Observed Variable"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{coord\_cartesian}\NormalTok{(}\AttributeTok{xlim =}\NormalTok{ x\_limits, }\AttributeTok{ylim =}\NormalTok{ y\_limits) }\SpecialCharTok{+} 
  \CommentTok{\# plot the intercepts }
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{data =}\NormalTok{ pointdata, }
             \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y, }\AttributeTok{color =}\NormalTok{ group), }
             \AttributeTok{inherit.aes =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{geom\_errorbar}\NormalTok{(}\AttributeTok{data =}\NormalTok{ pointdata,}
                \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{ymin =}\NormalTok{ ymin, }\AttributeTok{ymax =}\NormalTok{ ymax, }\AttributeTok{color =}\NormalTok{ group), }
                \AttributeTok{inherit.aes =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{width =}\NormalTok{ .}\DecValTok{10}\NormalTok{) }\SpecialCharTok{+} 
  \CommentTok{\# plot the slopes}
  \FunctionTok{geom\_abline}\NormalTok{(}\AttributeTok{data =}\NormalTok{ linedata,}
              \FunctionTok{aes}\NormalTok{(}\AttributeTok{slope =}\NormalTok{ slope, }\AttributeTok{intercept =}\NormalTok{ intercept, }\AttributeTok{color =}\NormalTok{ group)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_ribbon}\NormalTok{(}\AttributeTok{data =}\NormalTok{ ribbondata, }
              \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{ymin =}\NormalTok{ ymin, }\AttributeTok{ymax =}\NormalTok{ ymax, }\AttributeTok{fill =}\NormalTok{ group), }
              \AttributeTok{inherit.aes =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{alpha =}\NormalTok{ .}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{scale\_color\_discrete}\NormalTok{(}\AttributeTok{name =} \StringTok{"Group"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{scale\_fill\_discrete}\NormalTok{(}\AttributeTok{name =} \StringTok{"Group"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{axis.line.y =} \FunctionTok{element\_blank}\NormalTok{())}
  
  \CommentTok{\# make the latent means plot}
\NormalTok{  mean\_plot }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(latent\_means, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ lv, }\AttributeTok{fill =}\NormalTok{ group)) }\SpecialCharTok{+} 
    \FunctionTok{geom\_density}\NormalTok{(}\AttributeTok{alpha =}\NormalTok{ .}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+} 
    \FunctionTok{theme\_classic}\NormalTok{() }\SpecialCharTok{+} 
    \FunctionTok{xlab}\NormalTok{(}\StringTok{"Latent Variable"}\NormalTok{) }\SpecialCharTok{+} 
    \FunctionTok{ylab}\NormalTok{(}\StringTok{"Density"}\NormalTok{) }\SpecialCharTok{+} 
    \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{data =}\NormalTok{ latent\_means }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{group\_by}\NormalTok{(group) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{summarize}\NormalTok{(}\AttributeTok{mean =} \FunctionTok{mean}\NormalTok{(lv)), }
               \FunctionTok{aes}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ mean, }\AttributeTok{color =}\NormalTok{ group)) }\SpecialCharTok{+} 
    \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }\SpecialCharTok{+} 
    \FunctionTok{coord\_cartesian}\NormalTok{(}\AttributeTok{xlim =}\NormalTok{ x\_limits)}
  
\NormalTok{  y\_range }\OtherTok{=} \FunctionTok{abs}\NormalTok{(y\_limits[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ y\_limits[}\DecValTok{1}\NormalTok{])}
  
  \CommentTok{\# line up the two plots }
\NormalTok{  prow }\OtherTok{\textless{}{-}} \FunctionTok{plot\_grid}\NormalTok{(}
\NormalTok{    intercept\_plot }\SpecialCharTok{+} 
      \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Item Invariance"}\NormalTok{) }\SpecialCharTok{+} 
      \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }\SpecialCharTok{+} 
      \FunctionTok{annotation\_custom}\NormalTok{(}\FunctionTok{ggplotGrob}\NormalTok{(variance\_plot), }
                        \AttributeTok{xmin =}\NormalTok{ .}\DecValTok{25}\NormalTok{, }\AttributeTok{xmax =} \DecValTok{1}\NormalTok{, }
                        \AttributeTok{ymin =}\NormalTok{ y\_limits[}\DecValTok{1}\NormalTok{], }\AttributeTok{ymax =}\NormalTok{ y\_limits[}\DecValTok{2}\NormalTok{]}\SpecialCharTok{{-}}\NormalTok{y\_range}\SpecialCharTok{/}\FloatTok{1.8}\NormalTok{),}
\NormalTok{    mean\_plot }\SpecialCharTok{+} 
      \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Latent Mean Distribution"}\NormalTok{) }\SpecialCharTok{+} 
      \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{),}
    \AttributeTok{align =} \StringTok{\textquotesingle{}vh\textquotesingle{}}\NormalTok{,}
    \AttributeTok{hjust =} \SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}
    \AttributeTok{nrow =} \DecValTok{1}
\NormalTok{  )}
  
  \CommentTok{\# get the legend}
\NormalTok{  legend\_b }\OtherTok{\textless{}{-}} \FunctionTok{get\_legend}\NormalTok{(}
\NormalTok{    intercept\_plot }\SpecialCharTok{+} 
      \FunctionTok{guides}\NormalTok{(}\AttributeTok{color =} \FunctionTok{guide\_legend}\NormalTok{(}\AttributeTok{nrow =} \DecValTok{1}\NormalTok{)) }\SpecialCharTok{+}
      \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"bottom"}\NormalTok{)}
\NormalTok{  )}
  
  \CommentTok{\# send out the plot }
  \FunctionTok{plot\_grid}\NormalTok{(prow, legend\_b, }\AttributeTok{ncol =} \DecValTok{1}\NormalTok{, }\AttributeTok{rel\_heights =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, .}\DecValTok{1}\NormalTok{))}
  
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\normalsize

\hypertarget{model-fit-statistics}{%
\subsection{Model Fit Statistics}\label{model-fit-statistics}}

Model fit statistics are provided for each of the ten model combinations (invariant, three sizes for each ladings, intercepts, and residuals). These tables could be used to examine the traditional change in fit statistics cutoff rules of thumb (Cheung \& Rensvold, 2002), such as \(\Delta\) CFI or \(\Delta\) RMSEA, to the visualizations presented in the manuscript.

\begin{table}[tbp]

\begin{center}
\begin{threeparttable}

\caption{\label{tab:tab1}Model Fit for Invariant Model}

\begin{tabular}{lllllll}
\toprule
Model & AIC & BIC & CFI & TLI & RMSEA & SRMR\\
\midrule
Overall & 7,515.723 & 7,578.942 & 0.994 & 0.988 & 0.023 & 0.021\\
Group 1 & 3,765.749 & 3,818.571 & 0.976 & 0.953 & 0.047 & 0.031\\
Group 2 & 3,761.952 & 3,814.774 & 0.980 & 0.960 & 0.042 & 0.032\\
Configural & 7,527.701 & 7,654.140 & 0.978 & 0.956 & 0.045 & 0.032\\
Metric & 7,529.390 & 7,638.970 & 0.954 & 0.934 & 0.055 & 0.048\\
Scalar & 7,522.896 & 7,615.617 & 0.964 & 0.960 & 0.043 & 0.049\\
Strict & 7,519.512 & 7,591.160 & 0.957 & 0.963 & 0.041 & 0.059\\
\bottomrule
\end{tabular}

\end{threeparttable}
\end{center}

\end{table}

\begin{table}[tbp]

\begin{center}
\begin{threeparttable}

\caption{\label{tab:tab2}Model Fit for Small Differences in Loadings}

\begin{tabular}{lllllll}
\toprule
Model & AIC & BIC & CFI & TLI & RMSEA & SRMR\\
\midrule
Overall & 7,537.668 & 7,600.888 & 0.981 & 0.962 & 0.044 & 0.024\\
Group 1 & 3,765.749 & 3,818.571 & 0.976 & 0.953 & 0.047 & 0.031\\
Group 2 & 3,777.833 & 3,830.655 & 0.978 & 0.956 & 0.050 & 0.032\\
Configural & 7,543.582 & 7,670.020 & 0.977 & 0.955 & 0.048 & 0.032\\
Metric & 7,548.898 & 7,658.477 & 0.941 & 0.916 & 0.066 & 0.056\\
Scalar & 7,541.810 & 7,634.531 & 0.953 & 0.948 & 0.052 & 0.056\\
Strict & 7,541.658 & 7,613.307 & 0.935 & 0.943 & 0.054 & 0.071\\
\bottomrule
\end{tabular}

\end{threeparttable}
\end{center}

\end{table}

\begin{table}[tbp]

\begin{center}
\begin{threeparttable}

\caption{\label{tab:tab3}Model Fit for Medium Differences in Loadings}

\begin{tabular}{lllllll}
\toprule
Model & AIC & BIC & CFI & TLI & RMSEA & SRMR\\
\midrule
Overall & 7,554.550 & 7,617.769 & 0.972 & 0.945 & 0.052 & 0.027\\
Group 1 & 3,765.749 & 3,818.571 & 0.976 & 0.953 & 0.047 & 0.031\\
Group 2 & 3,784.923 & 3,837.745 & 0.998 & 0.996 & 0.016 & 0.025\\
Configural & 7,550.672 & 7,677.110 & 0.988 & 0.976 & 0.035 & 0.028\\
Metric & 7,562.714 & 7,672.294 & 0.926 & 0.894 & 0.074 & 0.063\\
Scalar & 7,556.859 & 7,649.580 & 0.933 & 0.926 & 0.062 & 0.064\\
Strict & 7,558.054 & 7,629.703 & 0.909 & 0.921 & 0.064 & 0.079\\
\bottomrule
\end{tabular}

\end{threeparttable}
\end{center}

\end{table}

\begin{table}[tbp]

\begin{center}
\begin{threeparttable}

\caption{\label{tab:tab4}Model Fit for Large Differences in Loadings}

\begin{tabular}{lllllll}
\toprule
Model & AIC & BIC & CFI & TLI & RMSEA & SRMR\\
\midrule
Overall & 7,662.989 & 7,726.209 & 0.984 & 0.969 & 0.045 & 0.022\\
Group 1 & 3,765.749 & 3,818.571 & 0.976 & 0.953 & 0.047 & 0.031\\
Group 2 & 3,857.210 & 3,910.032 & 0.968 & 0.936 & 0.076 & 0.033\\
Configural & 7,622.959 & 7,749.397 & 0.971 & 0.942 & 0.063 & 0.032\\
Metric & 7,659.191 & 7,768.771 & 0.854 & 0.792 & 0.120 & 0.085\\
Scalar & 7,652.603 & 7,745.325 & 0.862 & 0.846 & 0.103 & 0.085\\
Strict & 7,660.626 & 7,732.274 & 0.824 & 0.847 & 0.103 & 0.119\\
\bottomrule
\end{tabular}

\end{threeparttable}
\end{center}

\end{table}

\begin{table}[tbp]

\begin{center}
\begin{threeparttable}

\caption{\label{tab:tab5}Model Fit for Small Differences in Intercepts}

\begin{tabular}{lllllll}
\toprule
Model & AIC & BIC & CFI & TLI & RMSEA & SRMR\\
\midrule
Overall & 7,519.687 & 7,582.906 & 0.996 & 0.992 & 0.020 & 0.021\\
Group 1 & 3,765.749 & 3,818.571 & 0.976 & 0.953 & 0.047 & 0.031\\
Group 2 & 3,770.411 & 3,823.233 & 0.932 & 0.865 & 0.081 & 0.041\\
Configural & 7,536.160 & 7,662.598 & 0.954 & 0.908 & 0.066 & 0.036\\
Metric & 7,531.359 & 7,640.939 & 0.957 & 0.939 & 0.054 & 0.041\\
Scalar & 7,531.343 & 7,624.064 & 0.941 & 0.934 & 0.056 & 0.049\\
Strict & 7,523.535 & 7,595.184 & 0.952 & 0.959 & 0.045 & 0.052\\
\bottomrule
\end{tabular}

\end{threeparttable}
\end{center}

\end{table}

\begin{table}[tbp]

\begin{center}
\begin{threeparttable}

\caption{\label{tab:tab6}Model Fit for Medium Differences in Intercepts}

\begin{tabular}{lllllll}
\toprule
Model & AIC & BIC & CFI & TLI & RMSEA & SRMR\\
\midrule
Overall & 7,542.771 & 7,605.990 & 0.998 & 0.996 & 0.014 & 0.020\\
Group 1 & 3,765.749 & 3,818.571 & 0.976 & 0.953 & 0.047 & 0.031\\
Group 2 & 3,770.411 & 3,823.233 & 0.932 & 0.865 & 0.081 & 0.041\\
Configural & 7,536.160 & 7,662.598 & 0.954 & 0.908 & 0.066 & 0.036\\
Metric & 7,531.359 & 7,640.939 & 0.957 & 0.939 & 0.054 & 0.041\\
Scalar & 7,554.199 & 7,646.920 & 0.845 & 0.828 & 0.091 & 0.070\\
Strict & 7,546.383 & 7,618.032 & 0.857 & 0.876 & 0.077 & 0.071\\
\bottomrule
\end{tabular}

\end{threeparttable}
\end{center}

\end{table}

\begin{table}[tbp]

\begin{center}
\begin{threeparttable}

\caption{\label{tab:tab7}Model Fit for Large Differences in Intercepts}

\begin{tabular}{lllllll}
\toprule
Model & AIC & BIC & CFI & TLI & RMSEA & SRMR\\
\midrule
Overall & 7,579.167 & 7,642.386 & 1.000 & 1.000 & 0.000 & 0.019\\
Group 1 & 3,765.749 & 3,818.571 & 0.976 & 0.953 & 0.047 & 0.031\\
Group 2 & 3,770.411 & 3,823.233 & 0.932 & 0.865 & 0.081 & 0.041\\
Configural & 7,536.160 & 7,662.598 & 0.954 & 0.908 & 0.066 & 0.036\\
Metric & 7,531.359 & 7,640.939 & 0.957 & 0.939 & 0.054 & 0.041\\
Scalar & 7,590.291 & 7,683.013 & 0.695 & 0.661 & 0.128 & 0.097\\
Strict & 7,582.468 & 7,654.117 & 0.707 & 0.745 & 0.111 & 0.098\\
\bottomrule
\end{tabular}

\end{threeparttable}
\end{center}

\end{table}

\begin{table}[tbp]

\begin{center}
\begin{threeparttable}

\caption{\label{tab:tab8}Model Fit for Small Differences in Residuals}

\begin{tabular}{lllllll}
\toprule
Model & AIC & BIC & CFI & TLI & RMSEA & SRMR\\
\midrule
Overall & 7,449.492 & 7,512.711 & 1.000 & 1.008 & 0.000 & 0.014\\
Group 1 & 3,765.749 & 3,818.571 & 0.976 & 0.953 & 0.047 & 0.031\\
Group 2 & 3,693.319 & 3,746.141 & 1.000 & 1.009 & 0.000 & 0.022\\
Configural & 7,459.068 & 7,585.507 & 0.991 & 0.983 & 0.030 & 0.026\\
Metric & 7,461.406 & 7,570.986 & 0.966 & 0.952 & 0.049 & 0.049\\
Scalar & 7,455.854 & 7,548.575 & 0.972 & 0.969 & 0.039 & 0.051\\
Strict & 7,453.476 & 7,525.124 & 0.962 & 0.967 & 0.041 & 0.051\\
\bottomrule
\end{tabular}

\end{threeparttable}
\end{center}

\end{table}

\begin{table}[tbp]

\begin{center}
\begin{threeparttable}

\caption{\label{tab:tab9}Model Fit for Medium Differences in Residuals}

\begin{tabular}{lllllll}
\toprule
Model & AIC & BIC & CFI & TLI & RMSEA & SRMR\\
\midrule
Overall & 7,378.566 & 7,441.785 & 1.000 & 1.004 & 0.000 & 0.016\\
Group 1 & 3,765.749 & 3,818.571 & 0.976 & 0.953 & 0.047 & 0.031\\
Group 2 & 3,597.774 & 3,650.596 & 1.000 & 1.026 & 0.000 & 0.018\\
Configural & 7,363.523 & 7,489.961 & 0.997 & 0.994 & 0.018 & 0.025\\
Metric & 7,366.629 & 7,476.209 & 0.971 & 0.958 & 0.048 & 0.047\\
Scalar & 7,360.147 & 7,452.869 & 0.980 & 0.978 & 0.035 & 0.048\\
Strict & 7,382.532 & 7,454.180 & 0.879 & 0.895 & 0.076 & 0.072\\
\bottomrule
\end{tabular}

\end{threeparttable}
\end{center}

\end{table}

\begin{table}[tbp]

\begin{center}
\begin{threeparttable}

\caption{\label{tab:tab10}Model Fit for Large Differences in Residuals}

\begin{tabular}{lllllll}
\toprule
Model & AIC & BIC & CFI & TLI & RMSEA & SRMR\\
\midrule
Overall & 7,294.214 & 7,357.433 & 1.000 & 1.009 & 0.000 & 0.015\\
Group 1 & 3,765.749 & 3,818.571 & 0.976 & 0.953 & 0.047 & 0.031\\
Group 2 & 3,453.472 & 3,506.294 & 0.950 & 0.900 & 0.073 & 0.035\\
Configural & 7,219.221 & 7,345.659 & 0.962 & 0.925 & 0.061 & 0.033\\
Metric & 7,216.378 & 7,325.957 & 0.958 & 0.940 & 0.055 & 0.043\\
Scalar & 7,210.650 & 7,303.372 & 0.965 & 0.961 & 0.044 & 0.045\\
Strict & 7,297.887 & 7,369.535 & 0.595 & 0.648 & 0.133 & 0.176\\
\bottomrule
\end{tabular}

\end{threeparttable}
\end{center}

\end{table}


\end{document}
